{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEzMx_rigB2K"
      },
      "outputs": [],
      "source": [
        "!pip install scispacy\n",
        "!pip install spacy-transformers\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_scibert-0.5.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhXxaGjbMuNv"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxXnVgMjZ9jr",
        "outputId": "31da570e-ce29-4d6d-c060-cc9a27c4e358"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.20.3 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.20.3 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<scispacy.linking.EntityLinker at 0x7ff492445ed0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy_transformers\n",
        "import spacy\n",
        "import scispacy\n",
        "from scispacy.linking import EntityLinker\n",
        "\n",
        "nlp = spacy.load(\"en_core_sci_scibert\")\n",
        "nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": \"umls\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMIu_FpkNozw"
      },
      "outputs": [],
      "source": [
        "cs_text = \"\"\"\n",
        "Stable Diffusion is a deep learning, text-to-image model released by startup StabilityAI in 2022. \n",
        "It is primarily used to generate detailed images conditioned on text descriptions, \n",
        "though it can also be applied to other tasks such as inpainting, outpainting, and generating image-to-image translations guided by a text prompt.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fC2lWrdNeKS",
        "outputId": "7929bc80-55d6-4e03-8faf-23eb88cec651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stable ENTITY\n",
            "Diffusion ENTITY\n",
            "deep learning ENTITY\n",
            "text-to-image model ENTITY\n",
            "startup ENTITY\n",
            "StabilityAI ENTITY\n",
            "images ENTITY\n",
            "conditioned ENTITY\n",
            "descriptions ENTITY\n",
            "outpainting ENTITY\n",
            "image-to-image ENTITY\n",
            "text prompt ENTITY\n"
          ]
        }
      ],
      "source": [
        "output = nlp(cs_text)\n",
        "for ent in output.ents:\n",
        "  print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ebmMP0TFahc"
      },
      "source": [
        "# Prepare training data: train.spacy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ8BSeBZa_qz"
      },
      "source": [
        "prepare sciNER dataset for fineturning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDkjZgTIbCnn",
        "outputId": "4a27cba3-a7e6-46aa-e097-2696704ee4f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aDA84b8MbVwl",
        "outputId": "1352e91c-729e-49a7-8b93-e30e091c6f31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f5faf814-f364-46ee-9aa1-2b04e402b375\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clusters</th>\n",
              "      <th>sentences</th>\n",
              "      <th>ner</th>\n",
              "      <th>relations</th>\n",
              "      <th>doc_key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[17, 20], [23, 23]]]</td>\n",
              "      <td>[[English, is, shown, to, be, trans-context-fr...</td>\n",
              "      <td>[[[0, 0, Material], [10, 10, OtherScientificTe...</td>\n",
              "      <td>[[], [[29, 29, 31, 32, CONJUNCTION], [48, 49, ...</td>\n",
              "      <td>J87-1003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[62, 64], [90, 91], [96, 98], [112, 114]], [...</td>\n",
              "      <td>[[In, this, paper, ,, a, novel, method, to, le...</td>\n",
              "      <td>[[[6, 6, Method], [10, 12, OtherScientificTerm...</td>\n",
              "      <td>[[[6, 6, 10, 12, USED-FOR], [10, 12, 14, 16, U...</td>\n",
              "      <td>CVPR_2003_18_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[154, 154], [214, 214]], [[40, 44], [85, 85]...</td>\n",
              "      <td>[[In, this, paper, ,, we, present, a, digital,...</td>\n",
              "      <td>[[[7, 13, Method], [15, 21, Method], [23, 25, ...</td>\n",
              "      <td>[[[7, 13, 15, 21, USED-FOR], [15, 21, 23, 25, ...</td>\n",
              "      <td>INTERSPEECH_2013_31_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[3, 3], [110, 110]]]</td>\n",
              "      <td>[[We, propose, a, method, that, automatically,...</td>\n",
              "      <td>[[[3, 3, Generic], [7, 7, OtherScientificTerm]...</td>\n",
              "      <td>[[[3, 3, 7, 7, USED-FOR], [7, 7, 20, 23, USED-...</td>\n",
              "      <td>I05-5008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[35, 35], [69, 69]]]</td>\n",
              "      <td>[[Graph, unification, remains, the, most, expe...</td>\n",
              "      <td>[[[0, 1, Task], [8, 10, Task]], [[16, 17, Meth...</td>\n",
              "      <td>[[[0, 1, 8, 10, PART-OF]], [[16, 17, 22, 23, P...</td>\n",
              "      <td>C92-2068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>[[[97, 99], [128, 129], [181, 182]], [[93, 93]...</td>\n",
              "      <td>[[Learning, video, representation, is, not, a,...</td>\n",
              "      <td>[[[0, 2, Task]], [], [], [[67, 67, OtherScient...</td>\n",
              "      <td>[[], [], [], [], [[70, 71, 78, 83, USED-FOR]],...</td>\n",
              "      <td>IJCAI_2016_423_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>[[[36, 38], [64, 68], [70, 70], [159, 159]], [...</td>\n",
              "      <td>[[For, mobile, speech, application, ,, speaker...</td>\n",
              "      <td>[[[1, 3, Task], [5, 8, Metric], [10, 11, Metri...</td>\n",
              "      <td>[[[5, 8, 1, 3, FEATURE-OF], [5, 8, 10, 11, CON...</td>\n",
              "      <td>ICASSP_2016_14_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>[[[91, 91], [95, 98], [121, 121]], [[39, 41], ...</td>\n",
              "      <td>[[In, this, paper, ,, we, want, to, show, how,...</td>\n",
              "      <td>[[[10, 11, Method], [15, 25, Method], [39, 41,...</td>\n",
              "      <td>[[[10, 11, 15, 25, PART-OF], [39, 41, 44, 54, ...</td>\n",
              "      <td>A97-1027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>[[[29, 29], [46, 46], [97, 97]], [[48, 48], [6...</td>\n",
              "      <td>[[CriterionSM, Online, Essay, Evaluation, Serv...</td>\n",
              "      <td>[[[0, 4, Task], [15, 17, OtherScientificTerm],...</td>\n",
              "      <td>[[[15, 17, 0, 4, PART-OF], [21, 22, 15, 17, HY...</td>\n",
              "      <td>N04-1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[This, paper, presents, an, algorithm, for, l...</td>\n",
              "      <td>[[[4, 4, Generic], [6, 8, Task], [13, 14, Mate...</td>\n",
              "      <td>[[[4, 4, 6, 8, USED-FOR], [13, 14, 6, 8, FEATU...</td>\n",
              "      <td>CVPR_1992_10_abs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>350 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5faf814-f364-46ee-9aa1-2b04e402b375')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5faf814-f364-46ee-9aa1-2b04e402b375 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5faf814-f364-46ee-9aa1-2b04e402b375');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              clusters  \\\n",
              "0                               [[[17, 20], [23, 23]]]   \n",
              "1    [[[62, 64], [90, 91], [96, 98], [112, 114]], [...   \n",
              "2    [[[154, 154], [214, 214]], [[40, 44], [85, 85]...   \n",
              "3                               [[[3, 3], [110, 110]]]   \n",
              "4                               [[[35, 35], [69, 69]]]   \n",
              "..                                                 ...   \n",
              "345  [[[97, 99], [128, 129], [181, 182]], [[93, 93]...   \n",
              "346  [[[36, 38], [64, 68], [70, 70], [159, 159]], [...   \n",
              "347  [[[91, 91], [95, 98], [121, 121]], [[39, 41], ...   \n",
              "348  [[[29, 29], [46, 46], [97, 97]], [[48, 48], [6...   \n",
              "349                                                 []   \n",
              "\n",
              "                                             sentences  \\\n",
              "0    [[English, is, shown, to, be, trans-context-fr...   \n",
              "1    [[In, this, paper, ,, a, novel, method, to, le...   \n",
              "2    [[In, this, paper, ,, we, present, a, digital,...   \n",
              "3    [[We, propose, a, method, that, automatically,...   \n",
              "4    [[Graph, unification, remains, the, most, expe...   \n",
              "..                                                 ...   \n",
              "345  [[Learning, video, representation, is, not, a,...   \n",
              "346  [[For, mobile, speech, application, ,, speaker...   \n",
              "347  [[In, this, paper, ,, we, want, to, show, how,...   \n",
              "348  [[CriterionSM, Online, Essay, Evaluation, Serv...   \n",
              "349  [[This, paper, presents, an, algorithm, for, l...   \n",
              "\n",
              "                                                   ner  \\\n",
              "0    [[[0, 0, Material], [10, 10, OtherScientificTe...   \n",
              "1    [[[6, 6, Method], [10, 12, OtherScientificTerm...   \n",
              "2    [[[7, 13, Method], [15, 21, Method], [23, 25, ...   \n",
              "3    [[[3, 3, Generic], [7, 7, OtherScientificTerm]...   \n",
              "4    [[[0, 1, Task], [8, 10, Task]], [[16, 17, Meth...   \n",
              "..                                                 ...   \n",
              "345  [[[0, 2, Task]], [], [], [[67, 67, OtherScient...   \n",
              "346  [[[1, 3, Task], [5, 8, Metric], [10, 11, Metri...   \n",
              "347  [[[10, 11, Method], [15, 25, Method], [39, 41,...   \n",
              "348  [[[0, 4, Task], [15, 17, OtherScientificTerm],...   \n",
              "349  [[[4, 4, Generic], [6, 8, Task], [13, 14, Mate...   \n",
              "\n",
              "                                             relations  \\\n",
              "0    [[], [[29, 29, 31, 32, CONJUNCTION], [48, 49, ...   \n",
              "1    [[[6, 6, 10, 12, USED-FOR], [10, 12, 14, 16, U...   \n",
              "2    [[[7, 13, 15, 21, USED-FOR], [15, 21, 23, 25, ...   \n",
              "3    [[[3, 3, 7, 7, USED-FOR], [7, 7, 20, 23, USED-...   \n",
              "4    [[[0, 1, 8, 10, PART-OF]], [[16, 17, 22, 23, P...   \n",
              "..                                                 ...   \n",
              "345  [[], [], [], [], [[70, 71, 78, 83, USED-FOR]],...   \n",
              "346  [[[5, 8, 1, 3, FEATURE-OF], [5, 8, 10, 11, CON...   \n",
              "347  [[[10, 11, 15, 25, PART-OF], [39, 41, 44, 54, ...   \n",
              "348  [[[15, 17, 0, 4, PART-OF], [21, 22, 15, 17, HY...   \n",
              "349  [[[4, 4, 6, 8, USED-FOR], [13, 14, 6, 8, FEATU...   \n",
              "\n",
              "                     doc_key  \n",
              "0                   J87-1003  \n",
              "1           CVPR_2003_18_abs  \n",
              "2    INTERSPEECH_2013_31_abs  \n",
              "3                   I05-5008  \n",
              "4                   C92-2068  \n",
              "..                       ...  \n",
              "345       IJCAI_2016_423_abs  \n",
              "346       ICASSP_2016_14_abs  \n",
              "347                 A97-1027  \n",
              "348                 N04-1024  \n",
              "349         CVPR_1992_10_abs  \n",
              "\n",
              "[350 rows x 5 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_path = \"/content/drive/MyDrive/fine-turning-dataset/sciNER/train.json\"\n",
        "df_train = pd.read_json(train_data_path, lines=True)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeKv10WAgrZR",
        "outputId": "149e6a6c-d9eb-465d-e99b-fbf7c723d637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1762\n"
          ]
        }
      ],
      "source": [
        "processed_data = []\n",
        "for index, row in df_train.iterrows():\n",
        "  abstract = [\" \".join(i) for i in row[\"sentences\"]]\n",
        "  abstract = \" \".join(abstract)\n",
        "  abstract_list = [item for sublist in row[\"sentences\"] for item in sublist]\n",
        "  \n",
        "  for num in range(len(row[\"sentences\"])):\n",
        "    sentence = row[\"sentences\"][num]\n",
        "    entity_list = row['ner'][num]\n",
        "    if entity_list is not None and len(entity_list) != 0:\n",
        "      text = \" \".join(sentence)\n",
        "      updated_entity_list = []\n",
        "      \n",
        "      for entity_tuple in entity_list:\n",
        "        (start, end, label) = entity_tuple\n",
        "        phrase = \" \".join(abstract_list[start:end+1])\n",
        "        phrase = phrase + \" \"\n",
        "        if len(phrase) > 3 and phrase in text:\n",
        "          \n",
        "          updated_entity_list.append((text.index(phrase), text.index(phrase) + len(phrase)-1, label))\n",
        "      \n",
        "      entity = [tuple(sublist)for sublist in updated_entity_list]\n",
        "      data_tuple = (text, entity)\n",
        "      processed_data.append(data_tuple)\n",
        "\n",
        "print(len(processed_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1BrPJ21atUf"
      },
      "outputs": [],
      "source": [
        "print(processed_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taCxXspCtxKj",
        "outputId": "1c5e2eb6-3b0e-49b7-e590-b232a25d078b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English\n",
            "coordinations\n",
            "strictly syntactic cross-serial agreement\n"
          ]
        }
      ],
      "source": [
        "text = \"English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement .\"\n",
        "print(text[0:7])\n",
        "print(text[58:71])\n",
        "print(text[110:151])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK-dB1eguGCn",
        "outputId": "ae15c3d9-c2c9-4b2e-8fc0-d6c6730d14ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "agreement\n",
            "nouns\n",
            "reflexive pronouns\n",
            "grammatical number\n",
            "English\n",
            "grammatical gender\n",
            "languages\n",
            "French\n"
          ]
        }
      ],
      "source": [
        "text = \"The agreement in question involves number in nouns and reflexive pronouns and is syntactic rather than semantic in nature because grammatical number in English , like grammatical gender in languages such as French , is partly arbitrary .\"\n",
        "print(text[4:13])\n",
        "print(text[45:50])\n",
        "print(text[55:73])\n",
        "print(text[130:148])\n",
        "print(text[152:159])\n",
        "print(text[167:185])\n",
        "print(text[189:198])\n",
        "print(text[207:213])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Tbex5nvSGO",
        "outputId": "cf5a50b0-8580-49d6-ae36-1fec3e35e445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interchange Lemma\n",
            "English\n"
          ]
        }
      ],
      "source": [
        "text = \"The formal proof , which makes crucial use of the Interchange Lemma of Ogden et al. , is so constructed as to be valid even if English is presumed to contain grammatical sentences in which respectively operates across a pair of coordinate phrases one of whose members has fewer conjuncts than the other ; it thus goes through whatever the facts may be regarding constructions with unequal numbers of conjuncts in the scope of respectively , whereas other arguments have foundered on this problem .\"\n",
        "print(text[50:67])\n",
        "print(text[127:134])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyxy0l3WvpVQ",
        "outputId": "cb37439b-0a42-43e6-9492-59dfbf14996c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1762\n",
            "('English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement .', [(0, 7, 'Material'), (58, 71, 'OtherScientificTerm'), (110, 151, 'OtherScientificTerm')])\n"
          ]
        }
      ],
      "source": [
        "train_data = []\n",
        "index = 0\n",
        "for i in processed_data:\n",
        "  text, annotation = i\n",
        "  train_data.append((text, annotation))\n",
        "\n",
        "print(len(train_data))\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hpd15qInYas"
      },
      "source": [
        "https://dzone.com/articles/how-to-fine-tune-bert-transformer-with-spacy-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd4ygLkdtpNz"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "db = DocBin()\n",
        "index = 0\n",
        "for i in tqdm(train_data):\n",
        "  index += 1\n",
        "  for text, annotations in [i]:\n",
        "      print(index)\n",
        "      try:\n",
        "        doc = nlp(text)\n",
        "        ents = []\n",
        "        for start, end, label in annotations:\n",
        "            span = doc.char_span(start, end, label=label)\n",
        "            ents.append(span)\n",
        "        doc.ents = ents\n",
        "        db.add(doc)\n",
        "      except:\n",
        "        continue\n",
        "  \n",
        "db.to_disk(\"/content/train.spacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baei8vdVCRs1",
        "outputId": "dbb91538-c515-43c9-ac1e-842fb89486a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1623"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.from_disk(\"/content/train.spacy\")\n",
        "len(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCDzYaj3FnPs"
      },
      "source": [
        "# Prepare dev data: dev.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7nwCkC-6FrgH",
        "outputId": "acbecc90-1ad8-4246-aaa4-89c0648ccc7c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-48386fd3-34ba-41ec-8b9f-45634de420e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clusters</th>\n",
              "      <th>sentences</th>\n",
              "      <th>ner</th>\n",
              "      <th>relations</th>\n",
              "      <th>doc_key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[6, 17], [32, 32]], [[4, 4], [55, 55], [91, ...</td>\n",
              "      <td>[[This, paper, presents, an, algorithm, for, c...</td>\n",
              "      <td>[[[4, 4, Generic], [6, 17, Task], [20, 21, Mat...</td>\n",
              "      <td>[[[4, 4, 6, 17, USED-FOR], [20, 21, 4, 4, USED...</td>\n",
              "      <td>ICCV_2003_158_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[90, 91], [107, 107]]]</td>\n",
              "      <td>[[Past, work, of, generating, referring, expre...</td>\n",
              "      <td>[[[4, 5, OtherScientificTerm], [12, 13, OtherS...</td>\n",
              "      <td>[[], [], [], [], [], []]</td>\n",
              "      <td>C04-1096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[32, 32], [44, 44]], [[1, 2], [11, 11]], [[1...</td>\n",
              "      <td>[[An, entity-oriented, approach, to, restricte...</td>\n",
              "      <td>[[[1, 2, Method], [4, 5, Task]], [[11, 11, Gen...</td>\n",
              "      <td>[[[1, 2, 4, 5, USED-FOR]], [], [[32, 32, 37, 3...</td>\n",
              "      <td>P84-1047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[6, 11], [21, 21], [53, 53]], [[15, 16], [69...</td>\n",
              "      <td>[[This, paper, summarizes, the, formalism, of,...</td>\n",
              "      <td>[[[4, 11, Task], [6, 11, OtherScientificTerm],...</td>\n",
              "      <td>[[[15, 16, 19, 19, USED-FOR]], [], [[61, 62, 5...</td>\n",
              "      <td>C88-1066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[34, 36], [99, 101]], [[3, 5], [27, 27], [48...</td>\n",
              "      <td>[[We, present, a, text, mining, method, for, f...</td>\n",
              "      <td>[[[3, 5, Method], [8, 9, OtherScientificTerm],...</td>\n",
              "      <td>[[[3, 5, 8, 9, USED-FOR], [13, 14, 3, 5, USED-...</td>\n",
              "      <td>C04-1116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[[[28, 31], [68, 70], [96, 96], [123, 123]], [...</td>\n",
              "      <td>[[In, this, work, ,, we, present, a, technique...</td>\n",
              "      <td>[[[7, 7, Generic], [9, 10, Task], [17, 22, Oth...</td>\n",
              "      <td>[[[7, 7, 9, 10, USED-FOR], [7, 7, 28, 31, USED...</td>\n",
              "      <td>ICCV_2009_47_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[[[58, 59], [71, 72], [94, 95]], [[8, 10], [22...</td>\n",
              "      <td>[[An, attempt, has, been, made, to, use, an, A...</td>\n",
              "      <td>[[[8, 10, Method], [14, 15, Method]], [[22, 22...</td>\n",
              "      <td>[[[8, 10, 14, 15, HYPONYM-OF]], [[40, 41, 33, ...</td>\n",
              "      <td>C80-1073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[[[4, 6], [25, 25], [65, 65], [70, 70], [88, 8...</td>\n",
              "      <td>[[We, present, a, practically, unsupervised, l...</td>\n",
              "      <td>[[[4, 6, Method], [9, 10, OtherScientificTerm]...</td>\n",
              "      <td>[[[4, 6, 9, 10, USED-FOR], [15, 17, 20, 22, US...</td>\n",
              "      <td>H05-1041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[We, revisit, the, classical, decision-theore...</td>\n",
              "      <td>[[[3, 9, Task], [12, 14, Method]], [[32, 34, O...</td>\n",
              "      <td>[[[12, 14, 3, 9, USED-FOR]], [], [[50, 52, 55,...</td>\n",
              "      <td>NIPS_2014_18_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[[[51, 57], [74, 74]], [[7, 8], [70, 71]], [[3...</td>\n",
              "      <td>[[We, analyze, a, reweighted, version, of, the...</td>\n",
              "      <td>[[[3, 8, Method], [7, 8, Method], [12, 18, Tas...</td>\n",
              "      <td>[[[3, 8, 12, 18, USED-FOR], [12, 18, 22, 23, F...</td>\n",
              "      <td>NIPS_2014_10_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[[[8, 9], [33, 34]], [[11, 12], [36, 37]], [[3...</td>\n",
              "      <td>[[We, apply, a, decision, tree, based, approac...</td>\n",
              "      <td>[[[3, 6, Method], [8, 9, Task], [11, 12, Task]...</td>\n",
              "      <td>[[[3, 6, 8, 9, USED-FOR], [8, 9, 11, 12, USED-...</td>\n",
              "      <td>P03-1022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[[[4, 4], [57, 57], [94, 94], [149, 149]], [[6...</td>\n",
              "      <td>[[We, present, a, new, approach, for, building...</td>\n",
              "      <td>[[[4, 4, Generic], [11, 11, Method], [15, 16, ...</td>\n",
              "      <td>[[[4, 4, 11, 11, USED-FOR], [11, 11, 15, 16, U...</td>\n",
              "      <td>CVPR_2010_10_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[[[7, 9], [89, 89]]]</td>\n",
              "      <td>[[The, following, describes, recent, work, on,...</td>\n",
              "      <td>[[[7, 9, Method]], [[15, 16, Method]], [[25, 2...</td>\n",
              "      <td>[[], [], [[25, 26, 38, 41, USED-FOR], [30, 31,...</td>\n",
              "      <td>H91-1010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[[[2, 2], [76, 78]]]</td>\n",
              "      <td>[[A, new, approach, for, Interactive, Machine,...</td>\n",
              "      <td>[[[2, 2, Generic], [4, 6, Task]], [[44, 45, Me...</td>\n",
              "      <td>[[[2, 2, 4, 6, USED-FOR]], [], [], [[82, 82, 7...</td>\n",
              "      <td>C88-2160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[[[68, 70], [82, 83]], [[4, 4], [25, 25]]]</td>\n",
              "      <td>[[We, describe, a, novel, approach, to, statis...</td>\n",
              "      <td>[[[4, 4, Generic], [6, 8, Task], [11, 12, Othe...</td>\n",
              "      <td>[[[4, 4, 6, 8, USED-FOR], [11, 12, 4, 4, PART-...</td>\n",
              "      <td>P05-1034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[[[18, 20], [29, 29]]]</td>\n",
              "      <td>[[Video, provides, not, only, rich, visual, cu...</td>\n",
              "      <td>[[[0, 0, Material], [5, 6, OtherScientificTerm...</td>\n",
              "      <td>[[[5, 6, 0, 0, FEATURE-OF], [9, 9, 5, 6, HYPON...</td>\n",
              "      <td>CVPR_2011_292_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[[[6, 7], [81, 82], [164, 164], [189, 189]], [...</td>\n",
              "      <td>[[In, this, paper, ,, we, introduce, KAZE, fea...</td>\n",
              "      <td>[[[6, 7, Method], [11, 17, Method], [19, 21, O...</td>\n",
              "      <td>[[[6, 7, 11, 17, HYPONYM-OF], [19, 21, 11, 17,...</td>\n",
              "      <td>ECCV_2012_40_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[[[94, 97], [137, 137]]]</td>\n",
              "      <td>[[Semantic, Web, documents, that, encode, fact...</td>\n",
              "      <td>[[[0, 2, Material]], [[22, 23, Task], [25, 28,...</td>\n",
              "      <td>[[], [[22, 23, 31, 35, USED-FOR], [25, 28, 22,...</td>\n",
              "      <td>AAAI_2015_21_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[[[3, 3], [14, 14], [95, 95], [111, 111]]]</td>\n",
              "      <td>[[We, present, a, framework, for, the, fast, c...</td>\n",
              "      <td>[[[3, 3, Generic], [6, 11, Task]], [[14, 14, G...</td>\n",
              "      <td>[[[3, 3, 6, 11, USED-FOR]], [[20, 20, 14, 14, ...</td>\n",
              "      <td>C04-1147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[[[38, 38], [47, 47]], [[4, 4], [11, 11], [65,...</td>\n",
              "      <td>[[This, paper, introduces, a, system, for, cat...</td>\n",
              "      <td>[[[4, 4, Generic], [6, 8, Task]], [[11, 11, Ge...</td>\n",
              "      <td>[[[4, 4, 6, 8, USED-FOR]], [[16, 17, 11, 11, U...</td>\n",
              "      <td>A00-1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[[[14, 23], [26, 29], [58, 58], [144, 144]], [...</td>\n",
              "      <td>[[At, MIT, Lincoln, Laboratory, ,, we, have, b...</td>\n",
              "      <td>[[[10, 13, Method], [14, 23, Method]], [[26, 2...</td>\n",
              "      <td>[[[14, 23, 10, 13, HYPONYM-OF]], [[33, 34, 26,...</td>\n",
              "      <td>H01-1041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[[[1, 2], [33, 33], [53, 53], [69, 69]]]</td>\n",
              "      <td>[[The, JAVELIN, system, integrates, a, flexibl...</td>\n",
              "      <td>[[[1, 2, Method], [7, 8, Method], [13, 15, Met...</td>\n",
              "      <td>[[[1, 2, 19, 22, USED-FOR], [7, 8, 1, 2, PART-...</td>\n",
              "      <td>N03-4010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[[[34, 38], [53, 53]], [[7, 10], [29, 29]]]</td>\n",
              "      <td>[[We, present, the, first, application, of, th...</td>\n",
              "      <td>[[[7, 10, Method], [18, 20, Method], [22, 22, ...</td>\n",
              "      <td>[[[7, 10, 18, 20, USED-FOR], [7, 10, 22, 22, U...</td>\n",
              "      <td>P04-1030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[[[65, 66], [107, 107]]]</td>\n",
              "      <td>[[Image, composition, -LRB-, or, mosaicing, -R...</td>\n",
              "      <td>[[[0, 5, Task], [21, 24, Task]], [[35, 36, Tas...</td>\n",
              "      <td>[[[0, 5, 21, 24, PART-OF]], [[35, 36, 38, 38, ...</td>\n",
              "      <td>CVPR_2004_10_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[The, project, presented, here, is, a, part, ...</td>\n",
              "      <td>[[[17, 23, Method]], [[31, 38, Task], [40, 40,...</td>\n",
              "      <td>[[], [[40, 40, 31, 38, USED-FOR]], [[56, 60, 5...</td>\n",
              "      <td>L08-1260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[[[95, 95], [119, 119], [138, 138]], [[48, 53]...</td>\n",
              "      <td>[[Along, with, the, increasing, requirements, ...</td>\n",
              "      <td>[[[7, 9, Task], [11, 11, Material]], [], [[39,...</td>\n",
              "      <td>[[[7, 9, 11, 11, USED-FOR]], [], [], [[48, 53,...</td>\n",
              "      <td>IJCAI_2016_412_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[[[49, 51], [56, 56]], [[7, 9], [30, 30], [42,...</td>\n",
              "      <td>[[In, this, paper, ,, we, improve, an, unsuper...</td>\n",
              "      <td>[[[7, 9, Method], [12, 16, Method], [23, 25, T...</td>\n",
              "      <td>[[[12, 16, 7, 9, USED-FOR], [12, 16, 23, 25, U...</td>\n",
              "      <td>W03-0406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[[[0, 5], [36, 36], [39, 39], [77, 77], [101, ...</td>\n",
              "      <td>[[Dividing, sentences, in, chunks, of, words, ...</td>\n",
              "      <td>[[[0, 5, Task], [12, 12, Task], [14, 15, Task]...</td>\n",
              "      <td>[[[0, 5, 12, 12, USED-FOR], [0, 5, 14, 15, USE...</td>\n",
              "      <td>E99-1023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[[[8, 10], [29, 29]]]</td>\n",
              "      <td>[[In, this, paper, we, describe, and, evaluate...</td>\n",
              "      <td>[[[8, 10, Method]], [[21, 24, Material], [29, ...</td>\n",
              "      <td>[[], [[29, 29, 21, 24, USED-FOR], [32, 33, 29,...</td>\n",
              "      <td>N04-1008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[[[30, 31], [102, 102]], [[34, 35], [105, 106]...</td>\n",
              "      <td>[[In, this, paper, we, evaluate, four, objecti...</td>\n",
              "      <td>[[[7, 9, Metric], [13, 14, Task], [16, 17, Mat...</td>\n",
              "      <td>[[[7, 9, 13, 14, EVALUATE-FOR], [16, 17, 13, 1...</td>\n",
              "      <td>ICASSP_2011_598_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[[[31, 31], [33, 33], [126, 126], [138, 138]],...</td>\n",
              "      <td>[[A, '', graphics, for, vision, '', approach, ...</td>\n",
              "      <td>[[[1, 6, Method], [14, 14, Task], [17, 21, Mat...</td>\n",
              "      <td>[[[1, 6, 14, 14, USED-FOR], [17, 21, 14, 14, U...</td>\n",
              "      <td>CVPR_2003_10_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[[[27, 29], [55, 55], [70, 72]]]</td>\n",
              "      <td>[[Both, rhetorical, structure, and, punctuatio...</td>\n",
              "      <td>[[[1, 2, OtherScientificTerm], [4, 4, OtherSci...</td>\n",
              "      <td>[[[1, 2, 4, 4, CONJUNCTION], [1, 2, 9, 10, USE...</td>\n",
              "      <td>P06-3008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[[[25, 32], [76, 77], [90, 91]], [[73, 77], [8...</td>\n",
              "      <td>[[The, features, based, on, Markov, random, fi...</td>\n",
              "      <td>[[[1, 1, OtherScientificTerm], [4, 10, Method]...</td>\n",
              "      <td>[[[4, 10, 1, 1, USED-FOR]], [[25, 32, 34, 37, ...</td>\n",
              "      <td>CVPR_2003_11_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[[[60, 64], [79, 79]], [[15, 16], [100, 101]]]</td>\n",
              "      <td>[[Despite, much, recent, progress, on, accurat...</td>\n",
              "      <td>[[[6, 8, Task], [15, 16, Method], [22, 24, Met...</td>\n",
              "      <td>[[[15, 16, 6, 8, USED-FOR], [15, 16, 22, 24, C...</td>\n",
              "      <td>P05-1073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[[[43, 45], [58, 58], [114, 114]], [[50, 55], ...</td>\n",
              "      <td>[[One, of, the, major, problems, one, is, face...</td>\n",
              "      <td>[[[17, 17, OtherScientificTerm], [20, 20, Task...</td>\n",
              "      <td>[[], [[43, 45, 40, 40, USED-FOR], [50, 55, 43,...</td>\n",
              "      <td>E93-1023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[[[27, 27], [53, 53]], [[59, 59], [62, 62]], [...</td>\n",
              "      <td>[[This, paper, describes, the, framework, of, ...</td>\n",
              "      <td>[[[7, 11, Task], [14, 16, Method], [18, 24, Me...</td>\n",
              "      <td>[[[14, 16, 7, 11, USED-FOR], [18, 24, 14, 16, ...</td>\n",
              "      <td>C90-3014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[[[2, 3], [49, 49], [92, 92], [102, 102]], [[6...</td>\n",
              "      <td>[[In, some, auction, domains, ,, there, is, un...</td>\n",
              "      <td>[[[2, 3, Task]], [], [[49, 49, Generic], [52, ...</td>\n",
              "      <td>[[], [], [], [[85, 89, 92, 92, USED-FOR]], [],...</td>\n",
              "      <td>IJCAI_2016_413_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[[[8, 9], [18, 18], [28, 28], [49, 49], [75, 7...</td>\n",
              "      <td>[[In, this, paper, ,, we, will, describe, a, s...</td>\n",
              "      <td>[[[8, 9, Method], [15, 15, OtherScientificTerm...</td>\n",
              "      <td>[[[8, 9, 15, 15, USED-FOR]], [], [], [], [[81,...</td>\n",
              "      <td>C08-3010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[[[42, 43], [47, 47], [58, 59], [74, 75], [96,...</td>\n",
              "      <td>[[For, intelligent, interactive, systems, to, ...</td>\n",
              "      <td>[[[1, 3, Method], [13, 13, Generic]], [[28, 29...</td>\n",
              "      <td>[[], [[28, 29, 32, 32, PART-OF]], [], [], [], ...</td>\n",
              "      <td>J88-3002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[[[0, 2], [25, 25], [47, 47], [58, 60]], [[118...</td>\n",
              "      <td>[[Information, extraction, techniques, automat...</td>\n",
              "      <td>[[[0, 2, Method], [5, 6, Material], [8, 10, Ma...</td>\n",
              "      <td>[[[0, 2, 5, 6, USED-FOR], [8, 10, 0, 2, USED-F...</td>\n",
              "      <td>N04-4028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[[[77, 79], [101, 102]]]</td>\n",
              "      <td>[[In, this, paper, ,, we, use, the, informatio...</td>\n",
              "      <td>[[[7, 11, OtherScientificTerm], [16, 17, Task]...</td>\n",
              "      <td>[[[7, 11, 16, 17, USED-FOR], [7, 11, 24, 25, U...</td>\n",
              "      <td>H05-1005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[[[8, 8], [67, 69], [96, 96], [104, 104], [145...</td>\n",
              "      <td>[[In, this, paper, ,, we, propose, a, new, app...</td>\n",
              "      <td>[[[8, 8, Generic], [11, 16, Task], [20, 21, Me...</td>\n",
              "      <td>[[[8, 8, 11, 16, USED-FOR], [20, 21, 11, 16, E...</td>\n",
              "      <td>ICCV_2015_392_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[This, paper, describes, three, relatively, d...</td>\n",
              "      <td>[[[5, 6, Generic], [11, 15, Method], [17, 18, ...</td>\n",
              "      <td>[[[5, 6, 11, 15, PART-OF], [17, 18, 5, 6, HYPO...</td>\n",
              "      <td>H92-1017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[We, investigate, the, problem, of, fine-grai...</td>\n",
              "      <td>[[[5, 11, Task], [14, 16, OtherScientificTerm]...</td>\n",
              "      <td>[[[14, 16, 23, 26, USED-FOR]], [[74, 77, 87, 8...</td>\n",
              "      <td>CVPR_2016_416_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[[[124, 125], [158, 159]]]</td>\n",
              "      <td>[[In, this, paper, we, target, at, generating,...</td>\n",
              "      <td>[[[7, 9, OtherScientificTerm], [11, 12, Materi...</td>\n",
              "      <td>[[[11, 12, 7, 9, USED-FOR]], [[30, 32, 20, 25,...</td>\n",
              "      <td>CVPR_2015_303_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[[[57, 62], [133, 133]], [[6, 6], [15, 16], [1...</td>\n",
              "      <td>[[This, paper, reports, recent, research, into...</td>\n",
              "      <td>[[[6, 6, Generic], [8, 11, Task]], [[15, 16, G...</td>\n",
              "      <td>[[[6, 6, 8, 11, USED-FOR]], [], [], [[67, 67, ...</td>\n",
              "      <td>J81-1002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[[[52, 52], [65, 66]]]</td>\n",
              "      <td>[[This, paper, explores, the, issue, of, using...</td>\n",
              "      <td>[[[8, 9, OtherScientificTerm], [14, 15, Generi...</td>\n",
              "      <td>[[[8, 9, 14, 15, USED-FOR], [14, 15, 20, 20, U...</td>\n",
              "      <td>E99-1034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[[[4, 6], [27, 27], [126, 126]], [[21, 23], [4...</td>\n",
              "      <td>[[We, propose, a, new, phrase-based, translati...</td>\n",
              "      <td>[[[4, 6, Method], [8, 9, Method], [21, 23, Met...</td>\n",
              "      <td>[[[4, 6, 8, 9, CONJUNCTION]], [[43, 44, 46, 47...</td>\n",
              "      <td>N03-1017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[[[109, 109], [134, 134]], [[32, 33], [95, 96]]]</td>\n",
              "      <td>[[Color, is, known, to, be, highly, discrimina...</td>\n",
              "      <td>[[[9, 11, Task], [19, 20, Material], [24, 24, ...</td>\n",
              "      <td>[[], [[30, 30, 32, 33, USED-FOR], [30, 30, 36,...</td>\n",
              "      <td>CVPR_2011_293_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[We, describe, a, dialogue, system, that, wor...</td>\n",
              "      <td>[[[3, 4, Method]], [[18, 21, Method], [26, 26,...</td>\n",
              "      <td>[[], [[18, 21, 26, 26, USED-FOR], [18, 21, 28,...</td>\n",
              "      <td>P05-3001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48386fd3-34ba-41ec-8b9f-45634de420e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48386fd3-34ba-41ec-8b9f-45634de420e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48386fd3-34ba-41ec-8b9f-45634de420e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             clusters  \\\n",
              "0   [[[6, 17], [32, 32]], [[4, 4], [55, 55], [91, ...   \n",
              "1                            [[[90, 91], [107, 107]]]   \n",
              "2   [[[32, 32], [44, 44]], [[1, 2], [11, 11]], [[1...   \n",
              "3   [[[6, 11], [21, 21], [53, 53]], [[15, 16], [69...   \n",
              "4   [[[34, 36], [99, 101]], [[3, 5], [27, 27], [48...   \n",
              "5   [[[28, 31], [68, 70], [96, 96], [123, 123]], [...   \n",
              "6   [[[58, 59], [71, 72], [94, 95]], [[8, 10], [22...   \n",
              "7   [[[4, 6], [25, 25], [65, 65], [70, 70], [88, 8...   \n",
              "8                                                  []   \n",
              "9   [[[51, 57], [74, 74]], [[7, 8], [70, 71]], [[3...   \n",
              "10  [[[8, 9], [33, 34]], [[11, 12], [36, 37]], [[3...   \n",
              "11  [[[4, 4], [57, 57], [94, 94], [149, 149]], [[6...   \n",
              "12                               [[[7, 9], [89, 89]]]   \n",
              "13                               [[[2, 2], [76, 78]]]   \n",
              "14         [[[68, 70], [82, 83]], [[4, 4], [25, 25]]]   \n",
              "15                             [[[18, 20], [29, 29]]]   \n",
              "16  [[[6, 7], [81, 82], [164, 164], [189, 189]], [...   \n",
              "17                           [[[94, 97], [137, 137]]]   \n",
              "18         [[[3, 3], [14, 14], [95, 95], [111, 111]]]   \n",
              "19  [[[38, 38], [47, 47]], [[4, 4], [11, 11], [65,...   \n",
              "20  [[[14, 23], [26, 29], [58, 58], [144, 144]], [...   \n",
              "21           [[[1, 2], [33, 33], [53, 53], [69, 69]]]   \n",
              "22        [[[34, 38], [53, 53]], [[7, 10], [29, 29]]]   \n",
              "23                           [[[65, 66], [107, 107]]]   \n",
              "24                                                 []   \n",
              "25  [[[95, 95], [119, 119], [138, 138]], [[48, 53]...   \n",
              "26  [[[49, 51], [56, 56]], [[7, 9], [30, 30], [42,...   \n",
              "27  [[[0, 5], [36, 36], [39, 39], [77, 77], [101, ...   \n",
              "28                              [[[8, 10], [29, 29]]]   \n",
              "29  [[[30, 31], [102, 102]], [[34, 35], [105, 106]...   \n",
              "30  [[[31, 31], [33, 33], [126, 126], [138, 138]],...   \n",
              "31                   [[[27, 29], [55, 55], [70, 72]]]   \n",
              "32  [[[25, 32], [76, 77], [90, 91]], [[73, 77], [8...   \n",
              "33     [[[60, 64], [79, 79]], [[15, 16], [100, 101]]]   \n",
              "34  [[[43, 45], [58, 58], [114, 114]], [[50, 55], ...   \n",
              "35  [[[27, 27], [53, 53]], [[59, 59], [62, 62]], [...   \n",
              "36  [[[2, 3], [49, 49], [92, 92], [102, 102]], [[6...   \n",
              "37  [[[8, 9], [18, 18], [28, 28], [49, 49], [75, 7...   \n",
              "38  [[[42, 43], [47, 47], [58, 59], [74, 75], [96,...   \n",
              "39  [[[0, 2], [25, 25], [47, 47], [58, 60]], [[118...   \n",
              "40                           [[[77, 79], [101, 102]]]   \n",
              "41  [[[8, 8], [67, 69], [96, 96], [104, 104], [145...   \n",
              "42                                                 []   \n",
              "43                                                 []   \n",
              "44                         [[[124, 125], [158, 159]]]   \n",
              "45  [[[57, 62], [133, 133]], [[6, 6], [15, 16], [1...   \n",
              "46                             [[[52, 52], [65, 66]]]   \n",
              "47  [[[4, 6], [27, 27], [126, 126]], [[21, 23], [4...   \n",
              "48   [[[109, 109], [134, 134]], [[32, 33], [95, 96]]]   \n",
              "49                                                 []   \n",
              "\n",
              "                                            sentences  \\\n",
              "0   [[This, paper, presents, an, algorithm, for, c...   \n",
              "1   [[Past, work, of, generating, referring, expre...   \n",
              "2   [[An, entity-oriented, approach, to, restricte...   \n",
              "3   [[This, paper, summarizes, the, formalism, of,...   \n",
              "4   [[We, present, a, text, mining, method, for, f...   \n",
              "5   [[In, this, work, ,, we, present, a, technique...   \n",
              "6   [[An, attempt, has, been, made, to, use, an, A...   \n",
              "7   [[We, present, a, practically, unsupervised, l...   \n",
              "8   [[We, revisit, the, classical, decision-theore...   \n",
              "9   [[We, analyze, a, reweighted, version, of, the...   \n",
              "10  [[We, apply, a, decision, tree, based, approac...   \n",
              "11  [[We, present, a, new, approach, for, building...   \n",
              "12  [[The, following, describes, recent, work, on,...   \n",
              "13  [[A, new, approach, for, Interactive, Machine,...   \n",
              "14  [[We, describe, a, novel, approach, to, statis...   \n",
              "15  [[Video, provides, not, only, rich, visual, cu...   \n",
              "16  [[In, this, paper, ,, we, introduce, KAZE, fea...   \n",
              "17  [[Semantic, Web, documents, that, encode, fact...   \n",
              "18  [[We, present, a, framework, for, the, fast, c...   \n",
              "19  [[This, paper, introduces, a, system, for, cat...   \n",
              "20  [[At, MIT, Lincoln, Laboratory, ,, we, have, b...   \n",
              "21  [[The, JAVELIN, system, integrates, a, flexibl...   \n",
              "22  [[We, present, the, first, application, of, th...   \n",
              "23  [[Image, composition, -LRB-, or, mosaicing, -R...   \n",
              "24  [[The, project, presented, here, is, a, part, ...   \n",
              "25  [[Along, with, the, increasing, requirements, ...   \n",
              "26  [[In, this, paper, ,, we, improve, an, unsuper...   \n",
              "27  [[Dividing, sentences, in, chunks, of, words, ...   \n",
              "28  [[In, this, paper, we, describe, and, evaluate...   \n",
              "29  [[In, this, paper, we, evaluate, four, objecti...   \n",
              "30  [[A, '', graphics, for, vision, '', approach, ...   \n",
              "31  [[Both, rhetorical, structure, and, punctuatio...   \n",
              "32  [[The, features, based, on, Markov, random, fi...   \n",
              "33  [[Despite, much, recent, progress, on, accurat...   \n",
              "34  [[One, of, the, major, problems, one, is, face...   \n",
              "35  [[This, paper, describes, the, framework, of, ...   \n",
              "36  [[In, some, auction, domains, ,, there, is, un...   \n",
              "37  [[In, this, paper, ,, we, will, describe, a, s...   \n",
              "38  [[For, intelligent, interactive, systems, to, ...   \n",
              "39  [[Information, extraction, techniques, automat...   \n",
              "40  [[In, this, paper, ,, we, use, the, informatio...   \n",
              "41  [[In, this, paper, ,, we, propose, a, new, app...   \n",
              "42  [[This, paper, describes, three, relatively, d...   \n",
              "43  [[We, investigate, the, problem, of, fine-grai...   \n",
              "44  [[In, this, paper, we, target, at, generating,...   \n",
              "45  [[This, paper, reports, recent, research, into...   \n",
              "46  [[This, paper, explores, the, issue, of, using...   \n",
              "47  [[We, propose, a, new, phrase-based, translati...   \n",
              "48  [[Color, is, known, to, be, highly, discrimina...   \n",
              "49  [[We, describe, a, dialogue, system, that, wor...   \n",
              "\n",
              "                                                  ner  \\\n",
              "0   [[[4, 4, Generic], [6, 17, Task], [20, 21, Mat...   \n",
              "1   [[[4, 5, OtherScientificTerm], [12, 13, OtherS...   \n",
              "2   [[[1, 2, Method], [4, 5, Task]], [[11, 11, Gen...   \n",
              "3   [[[4, 11, Task], [6, 11, OtherScientificTerm],...   \n",
              "4   [[[3, 5, Method], [8, 9, OtherScientificTerm],...   \n",
              "5   [[[7, 7, Generic], [9, 10, Task], [17, 22, Oth...   \n",
              "6   [[[8, 10, Method], [14, 15, Method]], [[22, 22...   \n",
              "7   [[[4, 6, Method], [9, 10, OtherScientificTerm]...   \n",
              "8   [[[3, 9, Task], [12, 14, Method]], [[32, 34, O...   \n",
              "9   [[[3, 8, Method], [7, 8, Method], [12, 18, Tas...   \n",
              "10  [[[3, 6, Method], [8, 9, Task], [11, 12, Task]...   \n",
              "11  [[[4, 4, Generic], [11, 11, Method], [15, 16, ...   \n",
              "12  [[[7, 9, Method]], [[15, 16, Method]], [[25, 2...   \n",
              "13  [[[2, 2, Generic], [4, 6, Task]], [[44, 45, Me...   \n",
              "14  [[[4, 4, Generic], [6, 8, Task], [11, 12, Othe...   \n",
              "15  [[[0, 0, Material], [5, 6, OtherScientificTerm...   \n",
              "16  [[[6, 7, Method], [11, 17, Method], [19, 21, O...   \n",
              "17  [[[0, 2, Material]], [[22, 23, Task], [25, 28,...   \n",
              "18  [[[3, 3, Generic], [6, 11, Task]], [[14, 14, G...   \n",
              "19  [[[4, 4, Generic], [6, 8, Task]], [[11, 11, Ge...   \n",
              "20  [[[10, 13, Method], [14, 23, Method]], [[26, 2...   \n",
              "21  [[[1, 2, Method], [7, 8, Method], [13, 15, Met...   \n",
              "22  [[[7, 10, Method], [18, 20, Method], [22, 22, ...   \n",
              "23  [[[0, 5, Task], [21, 24, Task]], [[35, 36, Tas...   \n",
              "24  [[[17, 23, Method]], [[31, 38, Task], [40, 40,...   \n",
              "25  [[[7, 9, Task], [11, 11, Material]], [], [[39,...   \n",
              "26  [[[7, 9, Method], [12, 16, Method], [23, 25, T...   \n",
              "27  [[[0, 5, Task], [12, 12, Task], [14, 15, Task]...   \n",
              "28  [[[8, 10, Method]], [[21, 24, Material], [29, ...   \n",
              "29  [[[7, 9, Metric], [13, 14, Task], [16, 17, Mat...   \n",
              "30  [[[1, 6, Method], [14, 14, Task], [17, 21, Mat...   \n",
              "31  [[[1, 2, OtherScientificTerm], [4, 4, OtherSci...   \n",
              "32  [[[1, 1, OtherScientificTerm], [4, 10, Method]...   \n",
              "33  [[[6, 8, Task], [15, 16, Method], [22, 24, Met...   \n",
              "34  [[[17, 17, OtherScientificTerm], [20, 20, Task...   \n",
              "35  [[[7, 11, Task], [14, 16, Method], [18, 24, Me...   \n",
              "36  [[[2, 3, Task]], [], [[49, 49, Generic], [52, ...   \n",
              "37  [[[8, 9, Method], [15, 15, OtherScientificTerm...   \n",
              "38  [[[1, 3, Method], [13, 13, Generic]], [[28, 29...   \n",
              "39  [[[0, 2, Method], [5, 6, Material], [8, 10, Ma...   \n",
              "40  [[[7, 11, OtherScientificTerm], [16, 17, Task]...   \n",
              "41  [[[8, 8, Generic], [11, 16, Task], [20, 21, Me...   \n",
              "42  [[[5, 6, Generic], [11, 15, Method], [17, 18, ...   \n",
              "43  [[[5, 11, Task], [14, 16, OtherScientificTerm]...   \n",
              "44  [[[7, 9, OtherScientificTerm], [11, 12, Materi...   \n",
              "45  [[[6, 6, Generic], [8, 11, Task]], [[15, 16, G...   \n",
              "46  [[[8, 9, OtherScientificTerm], [14, 15, Generi...   \n",
              "47  [[[4, 6, Method], [8, 9, Method], [21, 23, Met...   \n",
              "48  [[[9, 11, Task], [19, 20, Material], [24, 24, ...   \n",
              "49  [[[3, 4, Method]], [[18, 21, Method], [26, 26,...   \n",
              "\n",
              "                                            relations              doc_key  \n",
              "0   [[[4, 4, 6, 17, USED-FOR], [20, 21, 4, 4, USED...    ICCV_2003_158_abs  \n",
              "1                            [[], [], [], [], [], []]             C04-1096  \n",
              "2   [[[1, 2, 4, 5, USED-FOR]], [], [[32, 32, 37, 3...             P84-1047  \n",
              "3   [[[15, 16, 19, 19, USED-FOR]], [], [[61, 62, 5...             C88-1066  \n",
              "4   [[[3, 5, 8, 9, USED-FOR], [13, 14, 3, 5, USED-...             C04-1116  \n",
              "5   [[[7, 7, 9, 10, USED-FOR], [7, 7, 28, 31, USED...     ICCV_2009_47_abs  \n",
              "6   [[[8, 10, 14, 15, HYPONYM-OF]], [[40, 41, 33, ...             C80-1073  \n",
              "7   [[[4, 6, 9, 10, USED-FOR], [15, 17, 20, 22, US...             H05-1041  \n",
              "8   [[[12, 14, 3, 9, USED-FOR]], [], [[50, 52, 55,...     NIPS_2014_18_abs  \n",
              "9   [[[3, 8, 12, 18, USED-FOR], [12, 18, 22, 23, F...     NIPS_2014_10_abs  \n",
              "10  [[[3, 6, 8, 9, USED-FOR], [8, 9, 11, 12, USED-...             P03-1022  \n",
              "11  [[[4, 4, 11, 11, USED-FOR], [11, 11, 15, 16, U...     CVPR_2010_10_abs  \n",
              "12  [[], [], [[25, 26, 38, 41, USED-FOR], [30, 31,...             H91-1010  \n",
              "13  [[[2, 2, 4, 6, USED-FOR]], [], [], [[82, 82, 7...             C88-2160  \n",
              "14  [[[4, 4, 6, 8, USED-FOR], [11, 12, 4, 4, PART-...             P05-1034  \n",
              "15  [[[5, 6, 0, 0, FEATURE-OF], [9, 9, 5, 6, HYPON...    CVPR_2011_292_abs  \n",
              "16  [[[6, 7, 11, 17, HYPONYM-OF], [19, 21, 11, 17,...     ECCV_2012_40_abs  \n",
              "17  [[], [[22, 23, 31, 35, USED-FOR], [25, 28, 22,...     AAAI_2015_21_abs  \n",
              "18  [[[3, 3, 6, 11, USED-FOR]], [[20, 20, 14, 14, ...             C04-1147  \n",
              "19  [[[4, 4, 6, 8, USED-FOR]], [[16, 17, 11, 11, U...             A00-1024  \n",
              "20  [[[14, 23, 10, 13, HYPONYM-OF]], [[33, 34, 26,...             H01-1041  \n",
              "21  [[[1, 2, 19, 22, USED-FOR], [7, 8, 1, 2, PART-...             N03-4010  \n",
              "22  [[[7, 10, 18, 20, USED-FOR], [7, 10, 22, 22, U...             P04-1030  \n",
              "23  [[[0, 5, 21, 24, PART-OF]], [[35, 36, 38, 38, ...     CVPR_2004_10_abs  \n",
              "24  [[], [[40, 40, 31, 38, USED-FOR]], [[56, 60, 5...             L08-1260  \n",
              "25  [[[7, 9, 11, 11, USED-FOR]], [], [], [[48, 53,...   IJCAI_2016_412_abs  \n",
              "26  [[[12, 16, 7, 9, USED-FOR], [12, 16, 23, 25, U...             W03-0406  \n",
              "27  [[[0, 5, 12, 12, USED-FOR], [0, 5, 14, 15, USE...             E99-1023  \n",
              "28  [[], [[29, 29, 21, 24, USED-FOR], [32, 33, 29,...             N04-1008  \n",
              "29  [[[7, 9, 13, 14, EVALUATE-FOR], [16, 17, 13, 1...  ICASSP_2011_598_abs  \n",
              "30  [[[1, 6, 14, 14, USED-FOR], [17, 21, 14, 14, U...     CVPR_2003_10_abs  \n",
              "31  [[[1, 2, 4, 4, CONJUNCTION], [1, 2, 9, 10, USE...             P06-3008  \n",
              "32  [[[4, 10, 1, 1, USED-FOR]], [[25, 32, 34, 37, ...     CVPR_2003_11_abs  \n",
              "33  [[[15, 16, 6, 8, USED-FOR], [15, 16, 22, 24, C...             P05-1073  \n",
              "34  [[], [[43, 45, 40, 40, USED-FOR], [50, 55, 43,...             E93-1023  \n",
              "35  [[[14, 16, 7, 11, USED-FOR], [18, 24, 14, 16, ...             C90-3014  \n",
              "36  [[], [], [], [[85, 89, 92, 92, USED-FOR]], [],...   IJCAI_2016_413_abs  \n",
              "37  [[[8, 9, 15, 15, USED-FOR]], [], [], [], [[81,...             C08-3010  \n",
              "38  [[], [[28, 29, 32, 32, PART-OF]], [], [], [], ...             J88-3002  \n",
              "39  [[[0, 2, 5, 6, USED-FOR], [8, 10, 0, 2, USED-F...             N04-4028  \n",
              "40  [[[7, 11, 16, 17, USED-FOR], [7, 11, 24, 25, U...             H05-1005  \n",
              "41  [[[8, 8, 11, 16, USED-FOR], [20, 21, 11, 16, E...    ICCV_2015_392_abs  \n",
              "42  [[[5, 6, 11, 15, PART-OF], [17, 18, 5, 6, HYPO...             H92-1017  \n",
              "43  [[[14, 16, 23, 26, USED-FOR]], [[74, 77, 87, 8...    CVPR_2016_416_abs  \n",
              "44  [[[11, 12, 7, 9, USED-FOR]], [[30, 32, 20, 25,...    CVPR_2015_303_abs  \n",
              "45  [[[6, 6, 8, 11, USED-FOR]], [], [], [[67, 67, ...             J81-1002  \n",
              "46  [[[8, 9, 14, 15, USED-FOR], [14, 15, 20, 20, U...             E99-1034  \n",
              "47  [[[4, 6, 8, 9, CONJUNCTION]], [[43, 44, 46, 47...             N03-1017  \n",
              "48  [[], [[30, 30, 32, 33, USED-FOR], [30, 30, 36,...    CVPR_2011_293_abs  \n",
              "49  [[], [[18, 21, 26, 26, USED-FOR], [18, 21, 28,...             P05-3001  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_data_path = \"/content/drive/MyDrive/fine-turning-dataset/sciNER/dev.json\"\n",
        "df_dev = pd.read_json(dev_data_path, lines=True)\n",
        "df_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGg19aVPF1KF",
        "outputId": "050e8bc9-4bae-46bf-cfbd-e8d0fc39f34c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "260\n"
          ]
        }
      ],
      "source": [
        "processed_data = []\n",
        "for index, row in df_dev.iterrows():\n",
        "  # if index == 39:\n",
        "  abstract = [\" \".join(i) for i in row[\"sentences\"]]\n",
        "  abstract = \" \".join(abstract)\n",
        "  abstract_list = [item for sublist in row[\"sentences\"] for item in sublist]\n",
        "  \n",
        "  for num in range(len(row[\"sentences\"])):\n",
        "    sentence = row[\"sentences\"][num]\n",
        "    entity_list = row['ner'][num]\n",
        "    if entity_list is not None and len(entity_list) != 0:\n",
        "      text = \" \".join(sentence)\n",
        "      updated_entity_list = []\n",
        "      for entity_tuple in entity_list:\n",
        "        (start, end, label) = entity_tuple\n",
        "        phrase = \" \".join(abstract_list[start:end+1])\n",
        "        phrase = phrase + \" \"\n",
        "        if len(phrase) > 3 and phrase in text:\n",
        "          \n",
        "          updated_entity_list.append((text.index(phrase), text.index(phrase) + len(phrase)-1, label))\n",
        "      \n",
        "      entity = [tuple(sublist)for sublist in updated_entity_list]\n",
        "      data_tuple = (text, entity)\n",
        "      processed_data.append(data_tuple)\n",
        "\n",
        "print(len(processed_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIC9MA-PF76t",
        "outputId": "875dbb17-f897-4314-e130-d1031242152a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "260\n"
          ]
        }
      ],
      "source": [
        "dev_data = []\n",
        "index = 0\n",
        "for i in processed_data:\n",
        "  text, annotation = i\n",
        "  dev_data.append((text, annotation))\n",
        "\n",
        "print(len(dev_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U65QRYT_GGk2"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "db = DocBin()\n",
        "index = 0\n",
        "for i in tqdm(dev_data):\n",
        "  index += 1\n",
        "  for text, annotations in [i]:\n",
        "      print(index)\n",
        "      try:\n",
        "        doc = nlp(text)\n",
        "        ents = []\n",
        "        for start, end, label in annotations:\n",
        "            span = doc.char_span(start, end, label=label)\n",
        "            ents.append(span)\n",
        "        doc.ents = ents\n",
        "        db.add(doc)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "db.to_disk(\"/content/dev.spacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbwwE82CCHU1",
        "outputId": "a4665d9a-e03d-4792-a798-e83649f36313"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "db = DocBin()\n",
        "db.from_disk(\"/content/dev.spacy\")\n",
        "len(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JZ1nEDGGRHx"
      },
      "source": [
        "# fine-turning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr2uJsjKHjqc"
      },
      "outputs": [],
      "source": [
        "!pip install scispacy\n",
        "!pip install spacy-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcqGGoHfHxHq"
      },
      "outputs": [],
      "source": [
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_scibert-0.5.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-TrM_qVpVIa",
        "outputId": "8c2d39e5-7815-407f-822d-47ff4c4f4dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2mâœ” Saved config\u001b[0m\n",
            "/content/config_spacy.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config_spacy.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy init fill-config /content/base_config.cfg /content/config_spacy.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaaeaaHYBEH5",
        "outputId": "fe470633-5e8d-4c83-e18d-16aeef095d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mâ„¹ Saving to output directory: /content/output\u001b[0m\n",
            "\u001b[38;5;4mâ„¹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-11-08 22:24:48,790] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-11-08 22:24:48,802] [INFO] Pipeline: ['transformer', 'ner']\n",
            "INFO:spacy:Pipeline: ['transformer', 'ner']\n",
            "[2022-11-08 22:24:48,802] [INFO] Resuming training for: ['ner']\n",
            "INFO:spacy:Resuming training for: ['ner']\n",
            "[2022-11-08 22:24:48,811] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2022-11-08 22:24:48,821] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-11-08 22:24:55,662] [INFO] Initialized pipeline components: ['transformer']\n",
            "INFO:spacy:Initialized pipeline components: ['transformer']\n",
            "\u001b[38;5;2mâœ” Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mâ„¹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mâ„¹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0           0.00    499.31    0.00    0.00    0.00    0.00\n",
            "  6     200           0.00  80298.32    0.00    0.00    0.00    0.00\n",
            " 13     400           0.00  48407.55   18.68   33.97   12.88    0.19\n",
            " 20     600           0.00  38498.55   29.26   40.62   22.87    0.29\n",
            " 27     800           0.00  36174.42   32.81   41.65   27.06    0.33\n",
            " 33    1000           0.00  38045.71   34.35   41.34   29.38    0.34\n",
            " 40    1200           0.00  38330.75   37.54   43.29   33.14    0.38\n",
            " 47    1400           0.00  37886.45   38.64   43.99   34.44    0.39\n",
            " 54    1600           0.00  36461.89   39.18   42.93   36.03    0.39\n",
            " 60    1800           0.00  33891.68   38.18   41.57   35.31    0.38\n",
            " 67    2000           0.00  31979.35   39.47   42.81   36.61    0.39\n",
            " 74    2200           0.00  30764.12   40.37   43.55   37.63    0.40\n",
            " 81    2400           0.00  29921.66   40.95   43.37   38.78    0.41\n",
            " 87    2600           0.00  29056.45   41.30   43.26   39.51    0.41\n",
            " 94    2800           0.00  28415.86   41.62   43.96   39.51    0.42\n",
            "101    3000           0.00  27853.66   41.39   43.29   39.65    0.41\n",
            "108    3200           0.00  27860.54   41.82   43.21   40.52    0.42\n",
            "114    3400           0.00  27859.34   42.37   44.57   40.38    0.42\n",
            "121    3600           0.00  27107.47   43.04   44.33   41.82    0.43\n",
            "128    3800           0.00  26526.48   43.57   44.80   42.40    0.44\n",
            "135    4000           0.00  26504.48   43.36   45.02   41.82    0.43\n",
            "142    4200           0.00  25511.90   43.82   46.02   41.82    0.44\n",
            "148    4400           0.00  25048.53   43.73   45.15   42.40    0.44\n",
            "155    4600           0.00  24478.93   45.08   46.88   43.42    0.45\n",
            "162    4800           0.00  24759.36   44.93   46.72   43.27    0.45\n",
            "169    5000           0.00  23857.46   45.19   46.62   43.85    0.45\n",
            "176    5200           0.00  23425.48   46.15   47.69   44.72    0.46\n",
            "182    5400           0.00  22810.87   46.02   47.39   44.72    0.46\n",
            "189    5600           0.00  21445.27   45.94   47.38   44.57    0.46\n",
            "196    5800           0.00  21581.12   45.56   46.60   44.57    0.46\n",
            "202    6000           0.00  21290.93   46.04   47.12   45.01    0.46\n",
            "209    6200           0.00  20579.35   46.34   47.42   45.30    0.46\n",
            "216    6400           0.00  19835.32   46.67   47.80   45.59    0.47\n",
            "222    6600           0.00  19886.22   46.55   47.72   45.44    0.47\n",
            "229    6800           0.00  19501.77   46.27   47.28   45.30    0.46\n",
            "236    7000           0.00  18977.50   46.67   47.80   45.59    0.47\n",
            "243    7200           0.00  18367.42   47.46   48.35   46.60    0.47\n",
            "249    7400           0.00  18153.32   46.77   48.02   45.59    0.47\n",
            "256    7600           0.00  17466.11   47.18   48.40   46.02    0.47\n",
            "263    7800           0.00  16913.38   46.61   47.52   45.73    0.47\n",
            "270    8000           0.00  17282.44   47.86   48.73   47.03    0.48\n",
            "276    8200           0.00  17062.78   48.01   48.88   47.18    0.48\n",
            "283    8400           0.00  16098.15   48.36   49.77   47.03    0.48\n",
            "290    8600           0.00  16403.47   47.92   49.16   46.74    0.48\n",
            "297    8800           0.00  15548.50   48.70   50.00   47.47    0.49\n",
            "303    9000           0.00  15434.72   48.58   50.08   47.18    0.49\n",
            "310    9200           0.00  15070.07   48.22   49.32   47.18    0.48\n",
            "317    9400           0.00  14937.01   48.89   50.23   47.61    0.49\n",
            "324    9600           0.00  14738.60   49.82   50.91   48.77    0.50\n",
            "330    9800           0.00  14800.43   48.74   50.08   47.47    0.49\n",
            "337   10000           0.00  14295.06   49.08   50.15   48.05    0.49\n",
            "344   10200           0.00  13895.28   49.33   50.53   48.19    0.49\n",
            "351   10400           0.00  13852.96   49.33   50.69   48.05    0.49\n",
            "357   10600           0.00  13321.96   48.86   49.85   47.90    0.49\n",
            "364   10800           0.00  13234.31   48.82   49.92   47.76    0.49\n",
            "370   11000           0.00  13399.70   48.82   49.77   47.90    0.49\n",
            "377   11200           0.00  12791.11   49.37   50.61   48.19    0.49\n",
            "\u001b[38;5;2mâœ” Saved pipeline to output directory\u001b[0m\n",
            "/content/output/model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train /content/config_spacy.cfg --output /content/output --paths.train /content/train.spacy --paths.dev /content/dev.spacy --gpu-id 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBRVWla4qNVl",
        "outputId": "9ed47541-0f8b-4961-81d4-8dd56338ac99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deep learning, text-to-image model Method\n",
            "StabilityAI OtherScientificTerm\n",
            "images Material\n",
            "text descriptions Task\n",
            "tasks Generic\n",
            "inpainting OtherScientificTerm\n",
            "outpainting OtherScientificTerm\n",
            "image-to-image translations Task\n",
            "text prompt Method\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"/content/output/model-best\")\n",
        "cs_text = \"\"\"\n",
        "Stable Diffusion is a deep learning, text-to-image model released by startup StabilityAI in 2022. \n",
        "It is primarily used to generate detailed images conditioned on text descriptions, \n",
        "though it can also be applied to other tasks such as inpainting, outpainting, and generating image-to-image translations guided by a text prompt.\n",
        "\"\"\"\n",
        "output = nlp(cs_text)\n",
        "for ent in output.ents:\n",
        "  print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfhWJaqSq5uG",
        "outputId": "b57e5fa5-c3c8-46af-8eb0-6197e6cd99cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/model-last/ (stored 0%)\n",
            "  adding: content/output/model-last/ner/ (stored 0%)\n",
            "  adding: content/output/model-last/ner/model (deflated 8%)\n",
            "  adding: content/output/model-last/ner/cfg (deflated 33%)\n",
            "  adding: content/output/model-last/ner/moves (deflated 69%)\n",
            "  adding: content/output/model-last/transformer/ (stored 0%)\n",
            "  adding: content/output/model-last/transformer/model (deflated 41%)\n",
            "  adding: content/output/model-last/transformer/cfg (stored 0%)\n",
            "  adding: content/output/model-last/meta.json (deflated 62%)\n",
            "  adding: content/output/model-last/vocab/ (stored 0%)\n",
            "  adding: content/output/model-last/vocab/vectors (deflated 45%)\n",
            "  adding: content/output/model-last/vocab/vectors.cfg (stored 0%)\n",
            "  adding: content/output/model-last/vocab/strings.json (deflated 75%)\n",
            "  adding: content/output/model-last/vocab/lookups.bin (stored 0%)\n",
            "  adding: content/output/model-last/vocab/key2row (stored 0%)\n",
            "  adding: content/output/model-last/tokenizer (deflated 81%)\n",
            "  adding: content/output/model-last/config.cfg (deflated 62%)\n",
            "  adding: content/output/model-best/ (stored 0%)\n",
            "  adding: content/output/model-best/ner/ (stored 0%)\n",
            "  adding: content/output/model-best/ner/model (deflated 8%)\n",
            "  adding: content/output/model-best/ner/cfg (deflated 33%)\n",
            "  adding: content/output/model-best/ner/moves (deflated 69%)\n",
            "  adding: content/output/model-best/transformer/ (stored 0%)\n",
            "  adding: content/output/model-best/transformer/model (deflated 41%)\n",
            "  adding: content/output/model-best/transformer/cfg (stored 0%)\n",
            "  adding: content/output/model-best/meta.json (deflated 63%)\n",
            "  adding: content/output/model-best/vocab/ (stored 0%)\n",
            "  adding: content/output/model-best/vocab/vectors (deflated 45%)\n",
            "  adding: content/output/model-best/vocab/vectors.cfg (stored 0%)\n",
            "  adding: content/output/model-best/vocab/strings.json (deflated 75%)\n",
            "  adding: content/output/model-best/vocab/lookups.bin (stored 0%)\n",
            "  adding: content/output/model-best/vocab/key2row (stored 0%)\n",
            "  adding: content/output/model-best/tokenizer (deflated 81%)\n",
            "  adding: content/output/model-best/config.cfg (deflated 62%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/fine_turned_output.zip /content/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "IGtTEd2OrE7T",
        "outputId": "c3d937c5-53b4-4516-b45d-079f72458fa2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_03ec6ed9-ce7c-4dde-a0ec-ba8c14fcddb0\", \"fine_turned_output.zip\", 605711425)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/fine_turned_output.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wCDzYaj3FnPs"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
