{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "i_VFl25_ps2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba43dd65-06b4-4eb5-bd82-bcce957326eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Design prompt (1 shot learning)"
      ],
      "metadata": {
        "id": "p5JdlCCv6dEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftqngpCPmIUm",
        "outputId": "5ca2189f-e5bb-4e0f-9bce-5b6e3b35e5a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task_description = \"Extract named entities from the description and label it from {[Task], [Method], [Material], [Matric], [Generic], [OtherScientificTerm]}\"\n",
        "\n",
        "few_shots = \"\"\"\n",
        "Description: English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement .\n",
        "Extract entities: English(Material), coordinations(OtherScientificTerm), strictly syntactic cross-serial agreement(OtherScientificTerm), \n",
        "\n",
        "Description: The agreement in question involves number in nouns and reflexive pronouns and is syntactic rather than semantic in nature because grammatical number in English , like grammatical gender in languages such as French.\n",
        "Extract entities: agreement(Generic), nouns(OtherScientificTerm), reflexive pronouns(OtherScientificTerm), grammatical number(OtherScientificTerm), English(Material), grammatical gender(OtherScientificTerm), languages(Material), French(Material), \n",
        "\n",
        "Description: We derived the dimensionality reduction and density estimation algorithm for unsupervised learning of object intrinsic representation , the obtained non-rigid part of object state reduces even to 2 dimensions .\n",
        "Extract entities: dimensionality reduction and density estimation algorithm(Method), unsupervised learning of object intrinsic representation(Task), object intrinsic representation(Method), non-rigid part of object state(OtherScientificTerm), \n",
        "\"\"\"\n",
        "\n",
        "header = task_description + \"\\n\" + few_shots"
      ],
      "metadata": {
        "id": "PdZHeQX-ljti"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(header))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-VL7xSQp8An",
        "outputId": "90ba0133-16dc-42a3-994c-e9fef6af4650"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "test_data_path = \"/content/drive/MyDrive/fine-turning-dataset/sciNER/test.json\"\n",
        "df_test = pd.read_json(test_data_path, lines=True)\n",
        "\n",
        "processed_sentence_list = []\n",
        "processed_entity_list = []\n",
        "for index, row in df_test.iterrows():\n",
        "  abstract = [\" \".join(i) for i in row[\"sentences\"]]\n",
        "  abstract = \" \".join(abstract)\n",
        "  abstract_list = [item for sublist in row[\"sentences\"] for item in sublist]\n",
        "  \n",
        "  for num in range(len(row[\"sentences\"])):\n",
        "    sentence = row[\"sentences\"][num]\n",
        "    entity_list = row['ner'][num]\n",
        "    if entity_list is not None and len(entity_list) != 0:\n",
        "      text = \" \".join(sentence)\n",
        "      updated_entity_list = []\n",
        "      # entity_list = entity_list.pop()\n",
        "      for i in entity_list:\n",
        "        if type(i) == list and len(i) == 3:\n",
        "          (start, end, label) = i\n",
        "          phrase = \" \".join(abstract_list[start:end+1])\n",
        "          phrase = phrase\n",
        "          if phrase in text:\n",
        "            updated_entity_list.append((phrase, label))\n",
        "      entity = [tuple(sublist)for sublist in updated_entity_list]\n",
        "      processed_sentence_list.append(text)\n",
        "\n",
        "      processed_entity_list.append(entity)\n",
        "\n",
        "prompt_list = [header + \"\\n\" + \"Description: \" + description + \"\\n\" + \"Extracted Named Entities:\" for description in processed_sentence_list]"
      ],
      "metadata": {
        "id": "cSs-F2QuvDzG"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(processed_sentence_list))\n",
        "print(len(processed_entity_list))\n",
        "print(len(prompt_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc3T33xR-iS_",
        "outputId": "f7ba2ff1-6081-446f-a31d-87ca15dfb5fe"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "529\n",
            "529\n",
            "529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(prompt_list[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JumiaIAimcDl",
        "outputId": "152ecc74-4257-46d9-82c0-fdac4aae0c0b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Extract named entities from the description and label it from {[Task], '\n",
            " '[Method], [Material], [Matric], [Generic], [OtherScientificTerm]}\\n'\n",
            " '\\n'\n",
            " 'Description: English is shown to be trans-context-free on the basis of '\n",
            " 'coordinations of the respectively type that involve strictly syntactic '\n",
            " 'cross-serial agreement .\\n'\n",
            " 'Extract entities: English(Material), coordinations(OtherScientificTerm), '\n",
            " 'strictly syntactic cross-serial agreement(OtherScientificTerm), \\n'\n",
            " '\\n'\n",
            " 'Description: The agreement in question involves number in nouns and '\n",
            " 'reflexive pronouns and is syntactic rather than semantic in nature because '\n",
            " 'grammatical number in English , like grammatical gender in languages such as '\n",
            " 'French.\\n'\n",
            " 'Extract entities: agreement(Generic), nouns(OtherScientificTerm), reflexive '\n",
            " 'pronouns(OtherScientificTerm), grammatical number(OtherScientificTerm), '\n",
            " 'English(Material), grammatical gender(OtherScientificTerm), '\n",
            " 'languages(Material), French(Material), \\n'\n",
            " '\\n'\n",
            " 'Description: We derived the dimensionality reduction and density estimation '\n",
            " 'algorithm for unsupervised learning of object intrinsic representation , the '\n",
            " 'obtained non-rigid part of object state reduces even to 2 dimensions .\\n'\n",
            " 'Extract entities: dimensionality reduction and density estimation '\n",
            " 'algorithm(Method), unsupervised learning of object intrinsic '\n",
            " 'representation(Task), object intrinsic representation(Method), non-rigid '\n",
            " 'part of object state(OtherScientificTerm), \\n'\n",
            " '\\n'\n",
            " 'Description: Recognition of proper nouns in Japanese text has been studied '\n",
            " 'as a part of the more general problem of morphological analysis in Japanese '\n",
            " 'text processing -LRB- -LSB- 1 -RSB- -LSB- 2 -RSB- -RRB- .\\n'\n",
            " 'Extracted Named Entities:')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in prompt_list:\n",
        "  if len(i) > 2048:\n",
        "    print(\"Lenth of prompt > 2048\")"
      ],
      "metadata": {
        "id": "YlgjlT11ozVJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "ccmKSk-ImrEz"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "GPT3_OPEN_AI_ENGINE = 'text-curie-001'\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def run_llm(prompts, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
        "    generated_texts = []\n",
        "    engine = GPT3_OPEN_AI_ENGINE \n",
        "    for p in tqdm(prompts, desc='Inference'):\n",
        "        response = openai.Completion.create(\n",
        "            engine=engine,\n",
        "            prompt=p,\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "            top_p=top_p,\n",
        "            frequency_penalty=frequency_penalty,\n",
        "            presence_penalty=presence_penalty\n",
        "        )\n",
        "        generated_text = response['choices'][0]['text']\n",
        "        generated_texts.append(generated_text)\n",
        "        time.sleep(1)\n",
        "    return generated_texts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 0.7\n",
        "max_tokens = 500\n",
        "top_p = 1\n",
        "frequency_penalty = 0\n",
        "presence_penalty = 0\n",
        "\n",
        "generated_texts = run_llm(prompt_list, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbIiDyiSp3uX",
        "outputId": "da02586c-234c-45ec-dd04-5fd595daa744"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 100%|██████████| 529/529 [12:36<00:00,  1.43s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percentile_list = pd.DataFrame(\n",
        "    {'sentence': processed_sentence_list,\n",
        "     'entity': processed_entity_list,\n",
        "     'generated text': generated_texts\n",
        "    })\n",
        "\n",
        "percentile_list.to_csv(\"gpt3_scierc.csv\", index = False)"
      ],
      "metadata": {
        "id": "gPIBpIOvF-QS"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentile_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kbPjkNqGO82k",
        "outputId": "feefe673-e5fc-43bf-e694-ac7036ab6d9b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sentence  \\\n",
              "0    Recognition of proper nouns in Japanese text h...   \n",
              "1    It has also been studied in the framework of J...   \n",
              "2    Our approach to the Multi-lingual Evaluation T...   \n",
              "3    Our morphological analyzer has done all the ne...   \n",
              "4                The analyzer is called `` Amorph '' .   \n",
              "..                                                 ...   \n",
              "524  Preliminary modeling and recognition results a...   \n",
              "525  Fast algorithms for nearest neighbor -LRB- NN ...   \n",
              "526  Here we develop an approach for 1 distance tha...   \n",
              "527  We show how this can efficiently be combined w...   \n",
              "528  We rigorously establish the correctness of the...   \n",
              "\n",
              "                                                entity  \\\n",
              "0    [(Recognition of proper nouns, Task), (proper ...   \n",
              "1    [(It, Generic), (Japanese information extracti...   \n",
              "2    [(approach, Generic), (Multi-lingual Evaluatio...   \n",
              "3    [(morphological analyzer, Method), (recognitio...   \n",
              "4        [(analyzer, Generic), (`` Amorph '', Method)]   \n",
              "..                                                 ...   \n",
              "524                              [(recognition, Task)]   \n",
              "525  [(Fast algorithms, Generic), (nearest neighbor...   \n",
              "526  [(approach, Generic), (1 distance, OtherScient...   \n",
              "527  [(this, Generic), (random-projection based met...   \n",
              "528  [(LSH, Method), (it, Generic), (alternatives, ...   \n",
              "\n",
              "                                        generated text  \n",
              "0     Recognition of proper nouns(Task), morphologi...  \n",
              "1     Japanese(OtherScientificTerm), information ex...  \n",
              "2     morphological analysis problem in Japanese(Ta...  \n",
              "3     proper names(Material), numerical and tempora...  \n",
              "4                          Amorph(OtherScientificTerm)  \n",
              "..                                                 ...  \n",
              "524   Recognition results(OtherScientificTerm), pre...  \n",
              "525   nearest neighbor -LRB- NN -RRB- search(Method...  \n",
              "526   embedding(Method), 1 distance(Method), exactl...  \n",
              "527   combination(Method), locality-sensitive hashi...  \n",
              "528   methodology(Method), correctness(Generic), co...  \n",
              "\n",
              "[529 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f1c1542-2ca7-4632-968b-d14d9080f38d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>entity</th>\n",
              "      <th>generated text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Recognition of proper nouns in Japanese text h...</td>\n",
              "      <td>[(Recognition of proper nouns, Task), (proper ...</td>\n",
              "      <td>Recognition of proper nouns(Task), morphologi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It has also been studied in the framework of J...</td>\n",
              "      <td>[(It, Generic), (Japanese information extracti...</td>\n",
              "      <td>Japanese(OtherScientificTerm), information ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Our approach to the Multi-lingual Evaluation T...</td>\n",
              "      <td>[(approach, Generic), (Multi-lingual Evaluatio...</td>\n",
              "      <td>morphological analysis problem in Japanese(Ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Our morphological analyzer has done all the ne...</td>\n",
              "      <td>[(morphological analyzer, Method), (recognitio...</td>\n",
              "      <td>proper names(Material), numerical and tempora...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The analyzer is called `` Amorph '' .</td>\n",
              "      <td>[(analyzer, Generic), (`` Amorph '', Method)]</td>\n",
              "      <td>Amorph(OtherScientificTerm)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>Preliminary modeling and recognition results a...</td>\n",
              "      <td>[(recognition, Task)]</td>\n",
              "      <td>Recognition results(OtherScientificTerm), pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>Fast algorithms for nearest neighbor -LRB- NN ...</td>\n",
              "      <td>[(Fast algorithms, Generic), (nearest neighbor...</td>\n",
              "      <td>nearest neighbor -LRB- NN -RRB- search(Method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>Here we develop an approach for 1 distance tha...</td>\n",
              "      <td>[(approach, Generic), (1 distance, OtherScient...</td>\n",
              "      <td>embedding(Method), 1 distance(Method), exactl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>We show how this can efficiently be combined w...</td>\n",
              "      <td>[(this, Generic), (random-projection based met...</td>\n",
              "      <td>combination(Method), locality-sensitive hashi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>We rigorously establish the correctness of the...</td>\n",
              "      <td>[(LSH, Method), (it, Generic), (alternatives, ...</td>\n",
              "      <td>methodology(Method), correctness(Generic), co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>529 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f1c1542-2ca7-4632-968b-d14d9080f38d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f1c1542-2ca7-4632-968b-d14d9080f38d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f1c1542-2ca7-4632-968b-d14d9080f38d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "pLwslqOczEBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/davidsbatista/NER-Evaluation.git\n",
        "!pip3 install scikit-learn\n",
        "!pip3 install nltk\n",
        "!pip3 install sklearn_crfsuite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft5BkA8HzGOE",
        "outputId": "b28e1e52-a1c6-45ac-9da0-b9e0403738d6"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NER-Evaluation'...\n",
            "remote: Enumerating objects: 234, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 234 (delta 0), reused 2 (delta 0), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (234/234), 82.22 KiB | 877.00 KiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.9/dist-packages (from sklearn_crfsuite) (4.65.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from sklearn_crfsuite) (0.8.10)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn_crfsuite\n",
            "Successfully installed python-crfsuite-0.9.9 sklearn_crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import sklearn_crfsuite\n",
        "\n",
        "from copy import deepcopy\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "\n",
        "from NER_Evaluation.ner_evaluation.ner_eval import collect_named_entities\n",
        "from NER_Evaluation.ner_evaluation.ner_eval import compute_metrics\n",
        "from NER_Evaluation.ner_evaluation.ner_eval import compute_precision_recall_wrapper\n",
        "from NER_Evaluation.ner_evaluation.ner_eval import namedtuple\n",
        "from NER_Evaluation.ner_evaluation.ner_eval import compute_precision_recall\n",
        "from NER_Evaluation.ner_evaluation.ner_eval import Evaluator"
      ],
      "metadata": {
        "id": "GTbrLgfPzI-e"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/gpt3_scierc.csv\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0pSVyv23zLh8",
        "outputId": "9f080c98-2bdb-40bd-eee5-2176d69ea884"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sentence  \\\n",
              "0    Recognition of proper nouns in Japanese text h...   \n",
              "1    It has also been studied in the framework of J...   \n",
              "2    Our approach to the Multi-lingual Evaluation T...   \n",
              "3    Our morphological analyzer has done all the ne...   \n",
              "4                The analyzer is called `` Amorph '' .   \n",
              "..                                                 ...   \n",
              "524  Preliminary modeling and recognition results a...   \n",
              "525  Fast algorithms for nearest neighbor -LRB- NN ...   \n",
              "526  Here we develop an approach for 1 distance tha...   \n",
              "527  We show how this can efficiently be combined w...   \n",
              "528  We rigorously establish the correctness of the...   \n",
              "\n",
              "                                                entity  \\\n",
              "0    [('Recognition of proper nouns', 'Task'), ('pr...   \n",
              "1    [('It', 'Generic'), ('Japanese information ext...   \n",
              "2    [('approach', 'Generic'), ('Multi-lingual Eval...   \n",
              "3    [('morphological analyzer', 'Method'), ('recog...   \n",
              "4    [('analyzer', 'Generic'), (\"`` Amorph ''\", 'Me...   \n",
              "..                                                 ...   \n",
              "524                          [('recognition', 'Task')]   \n",
              "525  [('Fast algorithms', 'Generic'), ('nearest nei...   \n",
              "526  [('approach', 'Generic'), ('1 distance', 'Othe...   \n",
              "527  [('this', 'Generic'), ('random-projection base...   \n",
              "528  [('LSH', 'Method'), ('it', 'Generic'), ('alter...   \n",
              "\n",
              "                                        generated text  \n",
              "0     Recognition of proper nouns(Task), morphologi...  \n",
              "1     Japanese(OtherScientificTerm), information ex...  \n",
              "2     morphological analysis problem in Japanese(Ta...  \n",
              "3     proper names(Material), numerical and tempora...  \n",
              "4                          Amorph(OtherScientificTerm)  \n",
              "..                                                 ...  \n",
              "524   Recognition results(OtherScientificTerm), pre...  \n",
              "525   nearest neighbor -LRB- NN -RRB- search(Method...  \n",
              "526   embedding(Method), 1 distance(Method), exactl...  \n",
              "527   combination(Method), locality-sensitive hashi...  \n",
              "528   methodology(Method), correctness(Generic), co...  \n",
              "\n",
              "[529 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecc055f8-0e36-4636-9720-b8a52b43253b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>entity</th>\n",
              "      <th>generated text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Recognition of proper nouns in Japanese text h...</td>\n",
              "      <td>[('Recognition of proper nouns', 'Task'), ('pr...</td>\n",
              "      <td>Recognition of proper nouns(Task), morphologi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It has also been studied in the framework of J...</td>\n",
              "      <td>[('It', 'Generic'), ('Japanese information ext...</td>\n",
              "      <td>Japanese(OtherScientificTerm), information ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Our approach to the Multi-lingual Evaluation T...</td>\n",
              "      <td>[('approach', 'Generic'), ('Multi-lingual Eval...</td>\n",
              "      <td>morphological analysis problem in Japanese(Ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Our morphological analyzer has done all the ne...</td>\n",
              "      <td>[('morphological analyzer', 'Method'), ('recog...</td>\n",
              "      <td>proper names(Material), numerical and tempora...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The analyzer is called `` Amorph '' .</td>\n",
              "      <td>[('analyzer', 'Generic'), (\"`` Amorph ''\", 'Me...</td>\n",
              "      <td>Amorph(OtherScientificTerm)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>Preliminary modeling and recognition results a...</td>\n",
              "      <td>[('recognition', 'Task')]</td>\n",
              "      <td>Recognition results(OtherScientificTerm), pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>Fast algorithms for nearest neighbor -LRB- NN ...</td>\n",
              "      <td>[('Fast algorithms', 'Generic'), ('nearest nei...</td>\n",
              "      <td>nearest neighbor -LRB- NN -RRB- search(Method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>Here we develop an approach for 1 distance tha...</td>\n",
              "      <td>[('approach', 'Generic'), ('1 distance', 'Othe...</td>\n",
              "      <td>embedding(Method), 1 distance(Method), exactl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>We show how this can efficiently be combined w...</td>\n",
              "      <td>[('this', 'Generic'), ('random-projection base...</td>\n",
              "      <td>combination(Method), locality-sensitive hashi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>We rigorously establish the correctness of the...</td>\n",
              "      <td>[('LSH', 'Method'), ('it', 'Generic'), ('alter...</td>\n",
              "      <td>methodology(Method), correctness(Generic), co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>529 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecc055f8-0e36-4636-9720-b8a52b43253b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecc055f8-0e36-4636-9720-b8a52b43253b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecc055f8-0e36-4636-9720-b8a52b43253b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_entities = []\n",
        "correct_entities = []\n",
        "Entity = namedtuple(\"Entity\", \"e_type start_offset end_offset\")\n",
        "\n",
        "def find_index_sub_list(sl,l):\n",
        "    sll=len(sl)\n",
        "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
        "        if l[ind:ind+sll]==sl:\n",
        "            return ind,ind+sll-1\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "\n",
        "  sentence = row[\"sentence\"]\n",
        "  \n",
        "  # sublist created for each sentence\n",
        "  sub_predicted_entities = []\n",
        "  sub_correct_entities = []\n",
        "\n",
        "  # process true labeled entity list\n",
        "  for entity in processed_entity_list[index]:\n",
        "    (text, label) = entity\n",
        "    start_index, end_index = find_index_sub_list(text.split(), sentence.split())\n",
        "    sub_correct_entities.append(Entity(label, start_index, end_index))\n",
        "  \n",
        "  # process predicted entity list\n",
        "  solution_list = row['entity']\n",
        "  try:\n",
        "    generated_list = row['generated text'].split(\", \")\n",
        "\n",
        "    for i in generated_list:\n",
        "      if \"(\" in i and \")\" in i:\n",
        "        entity = i.partition(\"(\")[0]\n",
        "        label = i.partition(\"(\")[2].partition(\")\")[0]\n",
        "        try:\n",
        "          start_index, end_index = find_index_sub_list(text.split(), sentence.split())\n",
        "          sub_predicted_entities.append(Entity(label, start_index, end_index))\n",
        "        except:\n",
        "          continue\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "  predicted_entities.append(sub_predicted_entities)\n",
        "  correct_entities.append(sub_correct_entities)\n",
        "\n",
        "print(len(predicted_entities))\n",
        "print(len(correct_entities))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWtkLONszPQ7",
        "outputId": "dacd6e4c-ddd6-4512-a7e2-6691f21bf6ae"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "529\n",
            "529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = ['Task', \"Method\", \"Material\", \"EvaluationMatric\", \"OtherScientificTerm\", \"Generic\"]\n",
        "\n",
        "metrics_results = {'correct': 0, 'incorrect': 0, 'partial': 0,\n",
        "                   'missed': 0, 'spurious': 0, 'possible': 0, 'actual': 0, 'precision': 0, 'recall': 0}\n",
        "\n",
        "# overall results\n",
        "results = {'strict': deepcopy(metrics_results),\n",
        "           'ent_type': deepcopy(metrics_results),\n",
        "           'partial':deepcopy(metrics_results),\n",
        "           'exact':deepcopy(metrics_results)\n",
        "          }\n",
        "\n",
        "for true_ents, pred_ents in zip(correct_entities, predicted_entities):\n",
        "\n",
        "  # compute results for one message\n",
        "  tmp_results, tmp_agg_results = compute_metrics(true_ents, pred_ents, tags)\n",
        "\n",
        "  # aggregate overall results\n",
        "  for eval_schema in results.keys():\n",
        "    for metric in metrics_results.keys():\n",
        "        results[eval_schema][metric] += tmp_results[eval_schema][metric]\n",
        "  \n",
        "  # Calculate global precision and recall\n",
        "  results = compute_precision_recall_wrapper(results)"
      ],
      "metadata": {
        "id": "9Z9vK8OtzSzz"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrXMA33SzWg1",
        "outputId": "cfa9fad1-1382-4cfc-ab9b-be62aa77a342"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ent_type': {'correct': 479,\n",
              "  'incorrect': 1133,\n",
              "  'partial': 0,\n",
              "  'missed': 1110,\n",
              "  'spurious': 79,\n",
              "  'possible': 2722,\n",
              "  'actual': 1691,\n",
              "  'precision': 0.283264340626848,\n",
              "  'recall': 0.17597354886113153},\n",
              " 'partial': {'correct': 1603,\n",
              "  'incorrect': 0,\n",
              "  'partial': 9,\n",
              "  'missed': 1110,\n",
              "  'spurious': 79,\n",
              "  'possible': 2722,\n",
              "  'actual': 1691,\n",
              "  'precision': 0.9506209343583678,\n",
              "  'recall': 0.5905584129316679},\n",
              " 'strict': {'correct': 477,\n",
              "  'incorrect': 1135,\n",
              "  'partial': 0,\n",
              "  'missed': 1110,\n",
              "  'spurious': 79,\n",
              "  'possible': 2722,\n",
              "  'actual': 1691,\n",
              "  'precision': 0.2820816085156712,\n",
              "  'recall': 0.17523879500367376},\n",
              " 'exact': {'correct': 1603,\n",
              "  'incorrect': 9,\n",
              "  'partial': 0,\n",
              "  'missed': 1110,\n",
              "  'spurious': 79,\n",
              "  'possible': 2722,\n",
              "  'actual': 1691,\n",
              "  'precision': 0.94795978710822,\n",
              "  'recall': 0.5889052167523879}}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    }
  ]
}