{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# More infomation of the model\n",
        "https://spacy.io/models/en#en_core_web_trf\n",
        "\n",
        "\n",
        "https://huggingface.co/roberta-base"
      ],
      "metadata": {
        "id": "lvfamBw90zhU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7316nPnuNZR"
      },
      "source": [
        "# Before Fine-turning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEzMx_rigB2K"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_trf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AhXxaGjbMuNv"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DxXnVgMjZ9jr"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_trf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wMIu_FpkNozw"
      },
      "outputs": [],
      "source": [
        "cs_text = \"\"\"\n",
        "Stable Diffusion is a deep learning, text-to-image model released by startup StabilityAI in 2022. \n",
        "It is primarily used to generate detailed images conditioned on text descriptions, \n",
        "though it can also be applied to other tasks such as inpainting, outpainting, and generating image-to-image translations guided by a text prompt.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-fC2lWrdNeKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a8d425e-ed02-4bbb-d0d1-e77637aa03c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StabilityAI ORG\n",
            "2022 DATE\n"
          ]
        }
      ],
      "source": [
        "output = nlp(cs_text)\n",
        "for ent in output.ents:\n",
        "  print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ebmMP0TFahc"
      },
      "source": [
        "# Prepare training data: train.spacy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ8BSeBZa_qz"
      },
      "source": [
        "prepare sciNER dataset for fineturning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fDkjZgTIbCnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d7487f-77a1-438f-9aa5-a6e00cd2f698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aDA84b8MbVwl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "c1c3a4fb-36f5-4eb3-985b-7a52e1a5b4a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            clusters  \\\n",
              "0                             [[[17, 20], [23, 23]]]   \n",
              "1  [[[62, 64], [90, 91], [96, 98], [112, 114]], [...   \n",
              "2  [[[154, 154], [214, 214]], [[40, 44], [85, 85]...   \n",
              "3                             [[[3, 3], [110, 110]]]   \n",
              "4                             [[[35, 35], [69, 69]]]   \n",
              "\n",
              "                                           sentences  \\\n",
              "0  [[English, is, shown, to, be, trans-context-fr...   \n",
              "1  [[In, this, paper, ,, a, novel, method, to, le...   \n",
              "2  [[In, this, paper, ,, we, present, a, digital,...   \n",
              "3  [[We, propose, a, method, that, automatically,...   \n",
              "4  [[Graph, unification, remains, the, most, expe...   \n",
              "\n",
              "                                                 ner  \\\n",
              "0  [[[0, 0, Material], [10, 10, OtherScientificTe...   \n",
              "1  [[[6, 6, Method], [10, 12, OtherScientificTerm...   \n",
              "2  [[[7, 13, Method], [15, 21, Method], [23, 25, ...   \n",
              "3  [[[3, 3, Generic], [7, 7, OtherScientificTerm]...   \n",
              "4  [[[0, 1, Task], [8, 10, Task]], [[16, 17, Meth...   \n",
              "\n",
              "                                           relations                  doc_key  \n",
              "0  [[], [[29, 29, 31, 32, CONJUNCTION], [48, 49, ...                 J87-1003  \n",
              "1  [[[6, 6, 10, 12, USED-FOR], [10, 12, 14, 16, U...         CVPR_2003_18_abs  \n",
              "2  [[[7, 13, 15, 21, USED-FOR], [15, 21, 23, 25, ...  INTERSPEECH_2013_31_abs  \n",
              "3  [[[3, 3, 7, 7, USED-FOR], [7, 7, 20, 23, USED-...                 I05-5008  \n",
              "4  [[[0, 1, 8, 10, PART-OF]], [[16, 17, 22, 23, P...                 C92-2068  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef91e071-9331-4f3e-b9c1-5380209145ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clusters</th>\n",
              "      <th>sentences</th>\n",
              "      <th>ner</th>\n",
              "      <th>relations</th>\n",
              "      <th>doc_key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[17, 20], [23, 23]]]</td>\n",
              "      <td>[[English, is, shown, to, be, trans-context-fr...</td>\n",
              "      <td>[[[0, 0, Material], [10, 10, OtherScientificTe...</td>\n",
              "      <td>[[], [[29, 29, 31, 32, CONJUNCTION], [48, 49, ...</td>\n",
              "      <td>J87-1003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[62, 64], [90, 91], [96, 98], [112, 114]], [...</td>\n",
              "      <td>[[In, this, paper, ,, a, novel, method, to, le...</td>\n",
              "      <td>[[[6, 6, Method], [10, 12, OtherScientificTerm...</td>\n",
              "      <td>[[[6, 6, 10, 12, USED-FOR], [10, 12, 14, 16, U...</td>\n",
              "      <td>CVPR_2003_18_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[154, 154], [214, 214]], [[40, 44], [85, 85]...</td>\n",
              "      <td>[[In, this, paper, ,, we, present, a, digital,...</td>\n",
              "      <td>[[[7, 13, Method], [15, 21, Method], [23, 25, ...</td>\n",
              "      <td>[[[7, 13, 15, 21, USED-FOR], [15, 21, 23, 25, ...</td>\n",
              "      <td>INTERSPEECH_2013_31_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[3, 3], [110, 110]]]</td>\n",
              "      <td>[[We, propose, a, method, that, automatically,...</td>\n",
              "      <td>[[[3, 3, Generic], [7, 7, OtherScientificTerm]...</td>\n",
              "      <td>[[[3, 3, 7, 7, USED-FOR], [7, 7, 20, 23, USED-...</td>\n",
              "      <td>I05-5008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[35, 35], [69, 69]]]</td>\n",
              "      <td>[[Graph, unification, remains, the, most, expe...</td>\n",
              "      <td>[[[0, 1, Task], [8, 10, Task]], [[16, 17, Meth...</td>\n",
              "      <td>[[[0, 1, 8, 10, PART-OF]], [[16, 17, 22, 23, P...</td>\n",
              "      <td>C92-2068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef91e071-9331-4f3e-b9c1-5380209145ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef91e071-9331-4f3e-b9c1-5380209145ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef91e071-9331-4f3e-b9c1-5380209145ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_data_path = \"/content/drive/MyDrive/fine-turning-dataset/sciNER/train.json\"\n",
        "df_train = pd.read_json(train_data_path, lines=True)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" \".join(df_train['sentences'][0][0]))\n",
        "print(df_train['ner'][0][0])"
      ],
      "metadata": {
        "id": "lV6znNfbeZHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4e195c-6415-4eaf-e5ea-32d718c8690e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement .\n",
            "[[0, 0, 'Material'], [10, 10, 'OtherScientificTerm'], [17, 20, 'OtherScientificTerm']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EeKv10WAgrZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb00074-aad5-49ea-b3da-9b86edc20b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1762\n"
          ]
        }
      ],
      "source": [
        "processed_data = []\n",
        "for index, row in df_train.iterrows():\n",
        "  abstract = [\" \".join(i) for i in row[\"sentences\"]]\n",
        "  abstract = \" \".join(abstract)\n",
        "  abstract_list = [item for sublist in row[\"sentences\"] for item in sublist]\n",
        "  \n",
        "  for num in range(len(row[\"sentences\"])):\n",
        "    sentence = row[\"sentences\"][num]\n",
        "    entity_list = row['ner'][num]\n",
        "    if entity_list is not None and len(entity_list) != 0:\n",
        "      text = \" \".join(sentence)\n",
        "      updated_entity_list = []\n",
        "      \n",
        "      for entity_tuple in entity_list:\n",
        "        (start, end, label) = entity_tuple\n",
        "        phrase = \" \".join(abstract_list[start:end+1])\n",
        "        phrase = phrase + \" \"\n",
        "        if len(phrase) > 3 and phrase in text:\n",
        "          \n",
        "          updated_entity_list.append((text.index(phrase), text.index(phrase) + len(phrase)-1, label))\n",
        "      \n",
        "      entity = [tuple(sublist)for sublist in updated_entity_list]\n",
        "      data_tuple = (text, entity)\n",
        "      processed_data.append(data_tuple)\n",
        "\n",
        "print(len(processed_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "D1BrPJ21atUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef441e3d-3fef-434b-81b6-8f8b3273cdcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement .', [(0, 7, 'Material'), (58, 71, 'OtherScientificTerm'), (110, 151, 'OtherScientificTerm')])\n"
          ]
        }
      ],
      "source": [
        "print(processed_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "taCxXspCtxKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438b4290-0a66-4654-9cda-3916d7cc3f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English\n",
            "coordinations\n",
            "strictly syntactic cross-serial agreement\n"
          ]
        }
      ],
      "source": [
        "text = \"English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement .\"\n",
        "print(text[0:7])\n",
        "print(text[58:71])\n",
        "print(text[110:151])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cK-dB1eguGCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3979e81-435b-4b4c-d9ee-5fc2609c6e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agreement\n",
            "nouns\n",
            "reflexive pronouns\n",
            "grammatical number\n",
            "English\n",
            "grammatical gender\n",
            "languages\n",
            "French\n"
          ]
        }
      ],
      "source": [
        "text = \"The agreement in question involves number in nouns and reflexive pronouns and is syntactic rather than semantic in nature because grammatical number in English , like grammatical gender in languages such as French , is partly arbitrary .\"\n",
        "print(text[4:13])\n",
        "print(text[45:50])\n",
        "print(text[55:73])\n",
        "print(text[130:148])\n",
        "print(text[152:159])\n",
        "print(text[167:185])\n",
        "print(text[189:198])\n",
        "print(text[207:213])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "r1Tbex5nvSGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ce6065-d9c4-4ebd-fbb5-0ec25390c0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interchange Lemma\n",
            "English\n"
          ]
        }
      ],
      "source": [
        "text = \"The formal proof , which makes crucial use of the Interchange Lemma of Ogden et al. , is so constructed as to be valid even if English is presumed to contain grammatical sentences in which respectively operates across a pair of coordinate phrases one of whose members has fewer conjuncts than the other ; it thus goes through whatever the facts may be regarding constructions with unequal numbers of conjuncts in the scope of respectively , whereas other arguments have foundered on this problem .\"\n",
        "print(text[50:67])\n",
        "print(text[127:134])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wyxy0l3WvpVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015da156-5657-4500-f126-4d662ae9f794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1762\n",
            "('English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement .', [(0, 7, 'Material'), (58, 71, 'OtherScientificTerm'), (110, 151, 'OtherScientificTerm')])\n"
          ]
        }
      ],
      "source": [
        "train_data = []\n",
        "index = 0\n",
        "for i in processed_data:\n",
        "  text, annotation = i\n",
        "  train_data.append((text, annotation))\n",
        "\n",
        "print(len(train_data))\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hpd15qInYas"
      },
      "source": [
        "https://dzone.com/articles/how-to-fine-tune-bert-transformer-with-spacy-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Yd4ygLkdtpNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8054004-1758-4579-d2b0-67ac55cb7fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1762/1762 [00:00<00:00, 2975.64it/s]\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "db = DocBin()\n",
        "index = 0\n",
        "for i in tqdm(train_data):\n",
        "  index += 1\n",
        "  for text, annotations in [i]:\n",
        "      # print(index)\n",
        "      try:\n",
        "        doc = nlp(text)\n",
        "        ents = []\n",
        "        for start, end, label in annotations:\n",
        "            span = doc.char_span(start, end, label=label)\n",
        "            ents.append(span)\n",
        "        doc.ents = ents\n",
        "        db.add(doc)\n",
        "      except:\n",
        "        continue\n",
        "  \n",
        "db.to_disk(\"/content/train.spacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "baei8vdVCRs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c513336-a674-4def-fc8b-e183701be11b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1623"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "db.from_disk(\"/content/train.spacy\")\n",
        "len(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCDzYaj3FnPs"
      },
      "source": [
        "# Prepare dev data: dev.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7nwCkC-6FrgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0427c0d-5560-4f4a-dbae-5a95e0502c03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             clusters  \\\n",
              "0   [[[6, 17], [32, 32]], [[4, 4], [55, 55], [91, ...   \n",
              "1                            [[[90, 91], [107, 107]]]   \n",
              "2   [[[32, 32], [44, 44]], [[1, 2], [11, 11]], [[1...   \n",
              "3   [[[6, 11], [21, 21], [53, 53]], [[15, 16], [69...   \n",
              "4   [[[34, 36], [99, 101]], [[3, 5], [27, 27], [48...   \n",
              "5   [[[28, 31], [68, 70], [96, 96], [123, 123]], [...   \n",
              "6   [[[58, 59], [71, 72], [94, 95]], [[8, 10], [22...   \n",
              "7   [[[4, 6], [25, 25], [65, 65], [70, 70], [88, 8...   \n",
              "8                                                  []   \n",
              "9   [[[51, 57], [74, 74]], [[7, 8], [70, 71]], [[3...   \n",
              "10  [[[8, 9], [33, 34]], [[11, 12], [36, 37]], [[3...   \n",
              "11  [[[4, 4], [57, 57], [94, 94], [149, 149]], [[6...   \n",
              "12                               [[[7, 9], [89, 89]]]   \n",
              "13                               [[[2, 2], [76, 78]]]   \n",
              "14         [[[68, 70], [82, 83]], [[4, 4], [25, 25]]]   \n",
              "15                             [[[18, 20], [29, 29]]]   \n",
              "16  [[[6, 7], [81, 82], [164, 164], [189, 189]], [...   \n",
              "17                           [[[94, 97], [137, 137]]]   \n",
              "18         [[[3, 3], [14, 14], [95, 95], [111, 111]]]   \n",
              "19  [[[38, 38], [47, 47]], [[4, 4], [11, 11], [65,...   \n",
              "20  [[[14, 23], [26, 29], [58, 58], [144, 144]], [...   \n",
              "21           [[[1, 2], [33, 33], [53, 53], [69, 69]]]   \n",
              "22        [[[34, 38], [53, 53]], [[7, 10], [29, 29]]]   \n",
              "23                           [[[65, 66], [107, 107]]]   \n",
              "24                                                 []   \n",
              "25  [[[95, 95], [119, 119], [138, 138]], [[48, 53]...   \n",
              "26  [[[49, 51], [56, 56]], [[7, 9], [30, 30], [42,...   \n",
              "27  [[[0, 5], [36, 36], [39, 39], [77, 77], [101, ...   \n",
              "28                              [[[8, 10], [29, 29]]]   \n",
              "29  [[[30, 31], [102, 102]], [[34, 35], [105, 106]...   \n",
              "30  [[[31, 31], [33, 33], [126, 126], [138, 138]],...   \n",
              "31                   [[[27, 29], [55, 55], [70, 72]]]   \n",
              "32  [[[25, 32], [76, 77], [90, 91]], [[73, 77], [8...   \n",
              "33     [[[60, 64], [79, 79]], [[15, 16], [100, 101]]]   \n",
              "34  [[[43, 45], [58, 58], [114, 114]], [[50, 55], ...   \n",
              "35  [[[27, 27], [53, 53]], [[59, 59], [62, 62]], [...   \n",
              "36  [[[2, 3], [49, 49], [92, 92], [102, 102]], [[6...   \n",
              "37  [[[8, 9], [18, 18], [28, 28], [49, 49], [75, 7...   \n",
              "38  [[[42, 43], [47, 47], [58, 59], [74, 75], [96,...   \n",
              "39  [[[0, 2], [25, 25], [47, 47], [58, 60]], [[118...   \n",
              "40                           [[[77, 79], [101, 102]]]   \n",
              "41  [[[8, 8], [67, 69], [96, 96], [104, 104], [145...   \n",
              "42                                                 []   \n",
              "43                                                 []   \n",
              "44                         [[[124, 125], [158, 159]]]   \n",
              "45  [[[57, 62], [133, 133]], [[6, 6], [15, 16], [1...   \n",
              "46                             [[[52, 52], [65, 66]]]   \n",
              "47  [[[4, 6], [27, 27], [126, 126]], [[21, 23], [4...   \n",
              "48   [[[109, 109], [134, 134]], [[32, 33], [95, 96]]]   \n",
              "49                                                 []   \n",
              "\n",
              "                                            sentences  \\\n",
              "0   [[This, paper, presents, an, algorithm, for, c...   \n",
              "1   [[Past, work, of, generating, referring, expre...   \n",
              "2   [[An, entity-oriented, approach, to, restricte...   \n",
              "3   [[This, paper, summarizes, the, formalism, of,...   \n",
              "4   [[We, present, a, text, mining, method, for, f...   \n",
              "5   [[In, this, work, ,, we, present, a, technique...   \n",
              "6   [[An, attempt, has, been, made, to, use, an, A...   \n",
              "7   [[We, present, a, practically, unsupervised, l...   \n",
              "8   [[We, revisit, the, classical, decision-theore...   \n",
              "9   [[We, analyze, a, reweighted, version, of, the...   \n",
              "10  [[We, apply, a, decision, tree, based, approac...   \n",
              "11  [[We, present, a, new, approach, for, building...   \n",
              "12  [[The, following, describes, recent, work, on,...   \n",
              "13  [[A, new, approach, for, Interactive, Machine,...   \n",
              "14  [[We, describe, a, novel, approach, to, statis...   \n",
              "15  [[Video, provides, not, only, rich, visual, cu...   \n",
              "16  [[In, this, paper, ,, we, introduce, KAZE, fea...   \n",
              "17  [[Semantic, Web, documents, that, encode, fact...   \n",
              "18  [[We, present, a, framework, for, the, fast, c...   \n",
              "19  [[This, paper, introduces, a, system, for, cat...   \n",
              "20  [[At, MIT, Lincoln, Laboratory, ,, we, have, b...   \n",
              "21  [[The, JAVELIN, system, integrates, a, flexibl...   \n",
              "22  [[We, present, the, first, application, of, th...   \n",
              "23  [[Image, composition, -LRB-, or, mosaicing, -R...   \n",
              "24  [[The, project, presented, here, is, a, part, ...   \n",
              "25  [[Along, with, the, increasing, requirements, ...   \n",
              "26  [[In, this, paper, ,, we, improve, an, unsuper...   \n",
              "27  [[Dividing, sentences, in, chunks, of, words, ...   \n",
              "28  [[In, this, paper, we, describe, and, evaluate...   \n",
              "29  [[In, this, paper, we, evaluate, four, objecti...   \n",
              "30  [[A, '', graphics, for, vision, '', approach, ...   \n",
              "31  [[Both, rhetorical, structure, and, punctuatio...   \n",
              "32  [[The, features, based, on, Markov, random, fi...   \n",
              "33  [[Despite, much, recent, progress, on, accurat...   \n",
              "34  [[One, of, the, major, problems, one, is, face...   \n",
              "35  [[This, paper, describes, the, framework, of, ...   \n",
              "36  [[In, some, auction, domains, ,, there, is, un...   \n",
              "37  [[In, this, paper, ,, we, will, describe, a, s...   \n",
              "38  [[For, intelligent, interactive, systems, to, ...   \n",
              "39  [[Information, extraction, techniques, automat...   \n",
              "40  [[In, this, paper, ,, we, use, the, informatio...   \n",
              "41  [[In, this, paper, ,, we, propose, a, new, app...   \n",
              "42  [[This, paper, describes, three, relatively, d...   \n",
              "43  [[We, investigate, the, problem, of, fine-grai...   \n",
              "44  [[In, this, paper, we, target, at, generating,...   \n",
              "45  [[This, paper, reports, recent, research, into...   \n",
              "46  [[This, paper, explores, the, issue, of, using...   \n",
              "47  [[We, propose, a, new, phrase-based, translati...   \n",
              "48  [[Color, is, known, to, be, highly, discrimina...   \n",
              "49  [[We, describe, a, dialogue, system, that, wor...   \n",
              "\n",
              "                                                  ner  \\\n",
              "0   [[[4, 4, Generic], [6, 17, Task], [20, 21, Mat...   \n",
              "1   [[[4, 5, OtherScientificTerm], [12, 13, OtherS...   \n",
              "2   [[[1, 2, Method], [4, 5, Task]], [[11, 11, Gen...   \n",
              "3   [[[4, 11, Task], [6, 11, OtherScientificTerm],...   \n",
              "4   [[[3, 5, Method], [8, 9, OtherScientificTerm],...   \n",
              "5   [[[7, 7, Generic], [9, 10, Task], [17, 22, Oth...   \n",
              "6   [[[8, 10, Method], [14, 15, Method]], [[22, 22...   \n",
              "7   [[[4, 6, Method], [9, 10, OtherScientificTerm]...   \n",
              "8   [[[3, 9, Task], [12, 14, Method]], [[32, 34, O...   \n",
              "9   [[[3, 8, Method], [7, 8, Method], [12, 18, Tas...   \n",
              "10  [[[3, 6, Method], [8, 9, Task], [11, 12, Task]...   \n",
              "11  [[[4, 4, Generic], [11, 11, Method], [15, 16, ...   \n",
              "12  [[[7, 9, Method]], [[15, 16, Method]], [[25, 2...   \n",
              "13  [[[2, 2, Generic], [4, 6, Task]], [[44, 45, Me...   \n",
              "14  [[[4, 4, Generic], [6, 8, Task], [11, 12, Othe...   \n",
              "15  [[[0, 0, Material], [5, 6, OtherScientificTerm...   \n",
              "16  [[[6, 7, Method], [11, 17, Method], [19, 21, O...   \n",
              "17  [[[0, 2, Material]], [[22, 23, Task], [25, 28,...   \n",
              "18  [[[3, 3, Generic], [6, 11, Task]], [[14, 14, G...   \n",
              "19  [[[4, 4, Generic], [6, 8, Task]], [[11, 11, Ge...   \n",
              "20  [[[10, 13, Method], [14, 23, Method]], [[26, 2...   \n",
              "21  [[[1, 2, Method], [7, 8, Method], [13, 15, Met...   \n",
              "22  [[[7, 10, Method], [18, 20, Method], [22, 22, ...   \n",
              "23  [[[0, 5, Task], [21, 24, Task]], [[35, 36, Tas...   \n",
              "24  [[[17, 23, Method]], [[31, 38, Task], [40, 40,...   \n",
              "25  [[[7, 9, Task], [11, 11, Material]], [], [[39,...   \n",
              "26  [[[7, 9, Method], [12, 16, Method], [23, 25, T...   \n",
              "27  [[[0, 5, Task], [12, 12, Task], [14, 15, Task]...   \n",
              "28  [[[8, 10, Method]], [[21, 24, Material], [29, ...   \n",
              "29  [[[7, 9, Metric], [13, 14, Task], [16, 17, Mat...   \n",
              "30  [[[1, 6, Method], [14, 14, Task], [17, 21, Mat...   \n",
              "31  [[[1, 2, OtherScientificTerm], [4, 4, OtherSci...   \n",
              "32  [[[1, 1, OtherScientificTerm], [4, 10, Method]...   \n",
              "33  [[[6, 8, Task], [15, 16, Method], [22, 24, Met...   \n",
              "34  [[[17, 17, OtherScientificTerm], [20, 20, Task...   \n",
              "35  [[[7, 11, Task], [14, 16, Method], [18, 24, Me...   \n",
              "36  [[[2, 3, Task]], [], [[49, 49, Generic], [52, ...   \n",
              "37  [[[8, 9, Method], [15, 15, OtherScientificTerm...   \n",
              "38  [[[1, 3, Method], [13, 13, Generic]], [[28, 29...   \n",
              "39  [[[0, 2, Method], [5, 6, Material], [8, 10, Ma...   \n",
              "40  [[[7, 11, OtherScientificTerm], [16, 17, Task]...   \n",
              "41  [[[8, 8, Generic], [11, 16, Task], [20, 21, Me...   \n",
              "42  [[[5, 6, Generic], [11, 15, Method], [17, 18, ...   \n",
              "43  [[[5, 11, Task], [14, 16, OtherScientificTerm]...   \n",
              "44  [[[7, 9, OtherScientificTerm], [11, 12, Materi...   \n",
              "45  [[[6, 6, Generic], [8, 11, Task]], [[15, 16, G...   \n",
              "46  [[[8, 9, OtherScientificTerm], [14, 15, Generi...   \n",
              "47  [[[4, 6, Method], [8, 9, Method], [21, 23, Met...   \n",
              "48  [[[9, 11, Task], [19, 20, Material], [24, 24, ...   \n",
              "49  [[[3, 4, Method]], [[18, 21, Method], [26, 26,...   \n",
              "\n",
              "                                            relations              doc_key  \n",
              "0   [[[4, 4, 6, 17, USED-FOR], [20, 21, 4, 4, USED...    ICCV_2003_158_abs  \n",
              "1                            [[], [], [], [], [], []]             C04-1096  \n",
              "2   [[[1, 2, 4, 5, USED-FOR]], [], [[32, 32, 37, 3...             P84-1047  \n",
              "3   [[[15, 16, 19, 19, USED-FOR]], [], [[61, 62, 5...             C88-1066  \n",
              "4   [[[3, 5, 8, 9, USED-FOR], [13, 14, 3, 5, USED-...             C04-1116  \n",
              "5   [[[7, 7, 9, 10, USED-FOR], [7, 7, 28, 31, USED...     ICCV_2009_47_abs  \n",
              "6   [[[8, 10, 14, 15, HYPONYM-OF]], [[40, 41, 33, ...             C80-1073  \n",
              "7   [[[4, 6, 9, 10, USED-FOR], [15, 17, 20, 22, US...             H05-1041  \n",
              "8   [[[12, 14, 3, 9, USED-FOR]], [], [[50, 52, 55,...     NIPS_2014_18_abs  \n",
              "9   [[[3, 8, 12, 18, USED-FOR], [12, 18, 22, 23, F...     NIPS_2014_10_abs  \n",
              "10  [[[3, 6, 8, 9, USED-FOR], [8, 9, 11, 12, USED-...             P03-1022  \n",
              "11  [[[4, 4, 11, 11, USED-FOR], [11, 11, 15, 16, U...     CVPR_2010_10_abs  \n",
              "12  [[], [], [[25, 26, 38, 41, USED-FOR], [30, 31,...             H91-1010  \n",
              "13  [[[2, 2, 4, 6, USED-FOR]], [], [], [[82, 82, 7...             C88-2160  \n",
              "14  [[[4, 4, 6, 8, USED-FOR], [11, 12, 4, 4, PART-...             P05-1034  \n",
              "15  [[[5, 6, 0, 0, FEATURE-OF], [9, 9, 5, 6, HYPON...    CVPR_2011_292_abs  \n",
              "16  [[[6, 7, 11, 17, HYPONYM-OF], [19, 21, 11, 17,...     ECCV_2012_40_abs  \n",
              "17  [[], [[22, 23, 31, 35, USED-FOR], [25, 28, 22,...     AAAI_2015_21_abs  \n",
              "18  [[[3, 3, 6, 11, USED-FOR]], [[20, 20, 14, 14, ...             C04-1147  \n",
              "19  [[[4, 4, 6, 8, USED-FOR]], [[16, 17, 11, 11, U...             A00-1024  \n",
              "20  [[[14, 23, 10, 13, HYPONYM-OF]], [[33, 34, 26,...             H01-1041  \n",
              "21  [[[1, 2, 19, 22, USED-FOR], [7, 8, 1, 2, PART-...             N03-4010  \n",
              "22  [[[7, 10, 18, 20, USED-FOR], [7, 10, 22, 22, U...             P04-1030  \n",
              "23  [[[0, 5, 21, 24, PART-OF]], [[35, 36, 38, 38, ...     CVPR_2004_10_abs  \n",
              "24  [[], [[40, 40, 31, 38, USED-FOR]], [[56, 60, 5...             L08-1260  \n",
              "25  [[[7, 9, 11, 11, USED-FOR]], [], [], [[48, 53,...   IJCAI_2016_412_abs  \n",
              "26  [[[12, 16, 7, 9, USED-FOR], [12, 16, 23, 25, U...             W03-0406  \n",
              "27  [[[0, 5, 12, 12, USED-FOR], [0, 5, 14, 15, USE...             E99-1023  \n",
              "28  [[], [[29, 29, 21, 24, USED-FOR], [32, 33, 29,...             N04-1008  \n",
              "29  [[[7, 9, 13, 14, EVALUATE-FOR], [16, 17, 13, 1...  ICASSP_2011_598_abs  \n",
              "30  [[[1, 6, 14, 14, USED-FOR], [17, 21, 14, 14, U...     CVPR_2003_10_abs  \n",
              "31  [[[1, 2, 4, 4, CONJUNCTION], [1, 2, 9, 10, USE...             P06-3008  \n",
              "32  [[[4, 10, 1, 1, USED-FOR]], [[25, 32, 34, 37, ...     CVPR_2003_11_abs  \n",
              "33  [[[15, 16, 6, 8, USED-FOR], [15, 16, 22, 24, C...             P05-1073  \n",
              "34  [[], [[43, 45, 40, 40, USED-FOR], [50, 55, 43,...             E93-1023  \n",
              "35  [[[14, 16, 7, 11, USED-FOR], [18, 24, 14, 16, ...             C90-3014  \n",
              "36  [[], [], [], [[85, 89, 92, 92, USED-FOR]], [],...   IJCAI_2016_413_abs  \n",
              "37  [[[8, 9, 15, 15, USED-FOR]], [], [], [], [[81,...             C08-3010  \n",
              "38  [[], [[28, 29, 32, 32, PART-OF]], [], [], [], ...             J88-3002  \n",
              "39  [[[0, 2, 5, 6, USED-FOR], [8, 10, 0, 2, USED-F...             N04-4028  \n",
              "40  [[[7, 11, 16, 17, USED-FOR], [7, 11, 24, 25, U...             H05-1005  \n",
              "41  [[[8, 8, 11, 16, USED-FOR], [20, 21, 11, 16, E...    ICCV_2015_392_abs  \n",
              "42  [[[5, 6, 11, 15, PART-OF], [17, 18, 5, 6, HYPO...             H92-1017  \n",
              "43  [[[14, 16, 23, 26, USED-FOR]], [[74, 77, 87, 8...    CVPR_2016_416_abs  \n",
              "44  [[[11, 12, 7, 9, USED-FOR]], [[30, 32, 20, 25,...    CVPR_2015_303_abs  \n",
              "45  [[[6, 6, 8, 11, USED-FOR]], [], [], [[67, 67, ...             J81-1002  \n",
              "46  [[[8, 9, 14, 15, USED-FOR], [14, 15, 20, 20, U...             E99-1034  \n",
              "47  [[[4, 6, 8, 9, CONJUNCTION]], [[43, 44, 46, 47...             N03-1017  \n",
              "48  [[], [[30, 30, 32, 33, USED-FOR], [30, 30, 36,...    CVPR_2011_293_abs  \n",
              "49  [[], [[18, 21, 26, 26, USED-FOR], [18, 21, 28,...             P05-3001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02a59b4b-61e4-4ccf-95e3-9be8b5da9807\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clusters</th>\n",
              "      <th>sentences</th>\n",
              "      <th>ner</th>\n",
              "      <th>relations</th>\n",
              "      <th>doc_key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[6, 17], [32, 32]], [[4, 4], [55, 55], [91, ...</td>\n",
              "      <td>[[This, paper, presents, an, algorithm, for, c...</td>\n",
              "      <td>[[[4, 4, Generic], [6, 17, Task], [20, 21, Mat...</td>\n",
              "      <td>[[[4, 4, 6, 17, USED-FOR], [20, 21, 4, 4, USED...</td>\n",
              "      <td>ICCV_2003_158_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[90, 91], [107, 107]]]</td>\n",
              "      <td>[[Past, work, of, generating, referring, expre...</td>\n",
              "      <td>[[[4, 5, OtherScientificTerm], [12, 13, OtherS...</td>\n",
              "      <td>[[], [], [], [], [], []]</td>\n",
              "      <td>C04-1096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[32, 32], [44, 44]], [[1, 2], [11, 11]], [[1...</td>\n",
              "      <td>[[An, entity-oriented, approach, to, restricte...</td>\n",
              "      <td>[[[1, 2, Method], [4, 5, Task]], [[11, 11, Gen...</td>\n",
              "      <td>[[[1, 2, 4, 5, USED-FOR]], [], [[32, 32, 37, 3...</td>\n",
              "      <td>P84-1047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[6, 11], [21, 21], [53, 53]], [[15, 16], [69...</td>\n",
              "      <td>[[This, paper, summarizes, the, formalism, of,...</td>\n",
              "      <td>[[[4, 11, Task], [6, 11, OtherScientificTerm],...</td>\n",
              "      <td>[[[15, 16, 19, 19, USED-FOR]], [], [[61, 62, 5...</td>\n",
              "      <td>C88-1066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[34, 36], [99, 101]], [[3, 5], [27, 27], [48...</td>\n",
              "      <td>[[We, present, a, text, mining, method, for, f...</td>\n",
              "      <td>[[[3, 5, Method], [8, 9, OtherScientificTerm],...</td>\n",
              "      <td>[[[3, 5, 8, 9, USED-FOR], [13, 14, 3, 5, USED-...</td>\n",
              "      <td>C04-1116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[[[28, 31], [68, 70], [96, 96], [123, 123]], [...</td>\n",
              "      <td>[[In, this, work, ,, we, present, a, technique...</td>\n",
              "      <td>[[[7, 7, Generic], [9, 10, Task], [17, 22, Oth...</td>\n",
              "      <td>[[[7, 7, 9, 10, USED-FOR], [7, 7, 28, 31, USED...</td>\n",
              "      <td>ICCV_2009_47_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[[[58, 59], [71, 72], [94, 95]], [[8, 10], [22...</td>\n",
              "      <td>[[An, attempt, has, been, made, to, use, an, A...</td>\n",
              "      <td>[[[8, 10, Method], [14, 15, Method]], [[22, 22...</td>\n",
              "      <td>[[[8, 10, 14, 15, HYPONYM-OF]], [[40, 41, 33, ...</td>\n",
              "      <td>C80-1073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[[[4, 6], [25, 25], [65, 65], [70, 70], [88, 8...</td>\n",
              "      <td>[[We, present, a, practically, unsupervised, l...</td>\n",
              "      <td>[[[4, 6, Method], [9, 10, OtherScientificTerm]...</td>\n",
              "      <td>[[[4, 6, 9, 10, USED-FOR], [15, 17, 20, 22, US...</td>\n",
              "      <td>H05-1041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[We, revisit, the, classical, decision-theore...</td>\n",
              "      <td>[[[3, 9, Task], [12, 14, Method]], [[32, 34, O...</td>\n",
              "      <td>[[[12, 14, 3, 9, USED-FOR]], [], [[50, 52, 55,...</td>\n",
              "      <td>NIPS_2014_18_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[[[51, 57], [74, 74]], [[7, 8], [70, 71]], [[3...</td>\n",
              "      <td>[[We, analyze, a, reweighted, version, of, the...</td>\n",
              "      <td>[[[3, 8, Method], [7, 8, Method], [12, 18, Tas...</td>\n",
              "      <td>[[[3, 8, 12, 18, USED-FOR], [12, 18, 22, 23, F...</td>\n",
              "      <td>NIPS_2014_10_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[[[8, 9], [33, 34]], [[11, 12], [36, 37]], [[3...</td>\n",
              "      <td>[[We, apply, a, decision, tree, based, approac...</td>\n",
              "      <td>[[[3, 6, Method], [8, 9, Task], [11, 12, Task]...</td>\n",
              "      <td>[[[3, 6, 8, 9, USED-FOR], [8, 9, 11, 12, USED-...</td>\n",
              "      <td>P03-1022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[[[4, 4], [57, 57], [94, 94], [149, 149]], [[6...</td>\n",
              "      <td>[[We, present, a, new, approach, for, building...</td>\n",
              "      <td>[[[4, 4, Generic], [11, 11, Method], [15, 16, ...</td>\n",
              "      <td>[[[4, 4, 11, 11, USED-FOR], [11, 11, 15, 16, U...</td>\n",
              "      <td>CVPR_2010_10_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[[[7, 9], [89, 89]]]</td>\n",
              "      <td>[[The, following, describes, recent, work, on,...</td>\n",
              "      <td>[[[7, 9, Method]], [[15, 16, Method]], [[25, 2...</td>\n",
              "      <td>[[], [], [[25, 26, 38, 41, USED-FOR], [30, 31,...</td>\n",
              "      <td>H91-1010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[[[2, 2], [76, 78]]]</td>\n",
              "      <td>[[A, new, approach, for, Interactive, Machine,...</td>\n",
              "      <td>[[[2, 2, Generic], [4, 6, Task]], [[44, 45, Me...</td>\n",
              "      <td>[[[2, 2, 4, 6, USED-FOR]], [], [], [[82, 82, 7...</td>\n",
              "      <td>C88-2160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[[[68, 70], [82, 83]], [[4, 4], [25, 25]]]</td>\n",
              "      <td>[[We, describe, a, novel, approach, to, statis...</td>\n",
              "      <td>[[[4, 4, Generic], [6, 8, Task], [11, 12, Othe...</td>\n",
              "      <td>[[[4, 4, 6, 8, USED-FOR], [11, 12, 4, 4, PART-...</td>\n",
              "      <td>P05-1034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[[[18, 20], [29, 29]]]</td>\n",
              "      <td>[[Video, provides, not, only, rich, visual, cu...</td>\n",
              "      <td>[[[0, 0, Material], [5, 6, OtherScientificTerm...</td>\n",
              "      <td>[[[5, 6, 0, 0, FEATURE-OF], [9, 9, 5, 6, HYPON...</td>\n",
              "      <td>CVPR_2011_292_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[[[6, 7], [81, 82], [164, 164], [189, 189]], [...</td>\n",
              "      <td>[[In, this, paper, ,, we, introduce, KAZE, fea...</td>\n",
              "      <td>[[[6, 7, Method], [11, 17, Method], [19, 21, O...</td>\n",
              "      <td>[[[6, 7, 11, 17, HYPONYM-OF], [19, 21, 11, 17,...</td>\n",
              "      <td>ECCV_2012_40_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[[[94, 97], [137, 137]]]</td>\n",
              "      <td>[[Semantic, Web, documents, that, encode, fact...</td>\n",
              "      <td>[[[0, 2, Material]], [[22, 23, Task], [25, 28,...</td>\n",
              "      <td>[[], [[22, 23, 31, 35, USED-FOR], [25, 28, 22,...</td>\n",
              "      <td>AAAI_2015_21_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[[[3, 3], [14, 14], [95, 95], [111, 111]]]</td>\n",
              "      <td>[[We, present, a, framework, for, the, fast, c...</td>\n",
              "      <td>[[[3, 3, Generic], [6, 11, Task]], [[14, 14, G...</td>\n",
              "      <td>[[[3, 3, 6, 11, USED-FOR]], [[20, 20, 14, 14, ...</td>\n",
              "      <td>C04-1147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[[[38, 38], [47, 47]], [[4, 4], [11, 11], [65,...</td>\n",
              "      <td>[[This, paper, introduces, a, system, for, cat...</td>\n",
              "      <td>[[[4, 4, Generic], [6, 8, Task]], [[11, 11, Ge...</td>\n",
              "      <td>[[[4, 4, 6, 8, USED-FOR]], [[16, 17, 11, 11, U...</td>\n",
              "      <td>A00-1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[[[14, 23], [26, 29], [58, 58], [144, 144]], [...</td>\n",
              "      <td>[[At, MIT, Lincoln, Laboratory, ,, we, have, b...</td>\n",
              "      <td>[[[10, 13, Method], [14, 23, Method]], [[26, 2...</td>\n",
              "      <td>[[[14, 23, 10, 13, HYPONYM-OF]], [[33, 34, 26,...</td>\n",
              "      <td>H01-1041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[[[1, 2], [33, 33], [53, 53], [69, 69]]]</td>\n",
              "      <td>[[The, JAVELIN, system, integrates, a, flexibl...</td>\n",
              "      <td>[[[1, 2, Method], [7, 8, Method], [13, 15, Met...</td>\n",
              "      <td>[[[1, 2, 19, 22, USED-FOR], [7, 8, 1, 2, PART-...</td>\n",
              "      <td>N03-4010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[[[34, 38], [53, 53]], [[7, 10], [29, 29]]]</td>\n",
              "      <td>[[We, present, the, first, application, of, th...</td>\n",
              "      <td>[[[7, 10, Method], [18, 20, Method], [22, 22, ...</td>\n",
              "      <td>[[[7, 10, 18, 20, USED-FOR], [7, 10, 22, 22, U...</td>\n",
              "      <td>P04-1030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[[[65, 66], [107, 107]]]</td>\n",
              "      <td>[[Image, composition, -LRB-, or, mosaicing, -R...</td>\n",
              "      <td>[[[0, 5, Task], [21, 24, Task]], [[35, 36, Tas...</td>\n",
              "      <td>[[[0, 5, 21, 24, PART-OF]], [[35, 36, 38, 38, ...</td>\n",
              "      <td>CVPR_2004_10_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[The, project, presented, here, is, a, part, ...</td>\n",
              "      <td>[[[17, 23, Method]], [[31, 38, Task], [40, 40,...</td>\n",
              "      <td>[[], [[40, 40, 31, 38, USED-FOR]], [[56, 60, 5...</td>\n",
              "      <td>L08-1260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[[[95, 95], [119, 119], [138, 138]], [[48, 53]...</td>\n",
              "      <td>[[Along, with, the, increasing, requirements, ...</td>\n",
              "      <td>[[[7, 9, Task], [11, 11, Material]], [], [[39,...</td>\n",
              "      <td>[[[7, 9, 11, 11, USED-FOR]], [], [], [[48, 53,...</td>\n",
              "      <td>IJCAI_2016_412_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[[[49, 51], [56, 56]], [[7, 9], [30, 30], [42,...</td>\n",
              "      <td>[[In, this, paper, ,, we, improve, an, unsuper...</td>\n",
              "      <td>[[[7, 9, Method], [12, 16, Method], [23, 25, T...</td>\n",
              "      <td>[[[12, 16, 7, 9, USED-FOR], [12, 16, 23, 25, U...</td>\n",
              "      <td>W03-0406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[[[0, 5], [36, 36], [39, 39], [77, 77], [101, ...</td>\n",
              "      <td>[[Dividing, sentences, in, chunks, of, words, ...</td>\n",
              "      <td>[[[0, 5, Task], [12, 12, Task], [14, 15, Task]...</td>\n",
              "      <td>[[[0, 5, 12, 12, USED-FOR], [0, 5, 14, 15, USE...</td>\n",
              "      <td>E99-1023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[[[8, 10], [29, 29]]]</td>\n",
              "      <td>[[In, this, paper, we, describe, and, evaluate...</td>\n",
              "      <td>[[[8, 10, Method]], [[21, 24, Material], [29, ...</td>\n",
              "      <td>[[], [[29, 29, 21, 24, USED-FOR], [32, 33, 29,...</td>\n",
              "      <td>N04-1008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[[[30, 31], [102, 102]], [[34, 35], [105, 106]...</td>\n",
              "      <td>[[In, this, paper, we, evaluate, four, objecti...</td>\n",
              "      <td>[[[7, 9, Metric], [13, 14, Task], [16, 17, Mat...</td>\n",
              "      <td>[[[7, 9, 13, 14, EVALUATE-FOR], [16, 17, 13, 1...</td>\n",
              "      <td>ICASSP_2011_598_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[[[31, 31], [33, 33], [126, 126], [138, 138]],...</td>\n",
              "      <td>[[A, '', graphics, for, vision, '', approach, ...</td>\n",
              "      <td>[[[1, 6, Method], [14, 14, Task], [17, 21, Mat...</td>\n",
              "      <td>[[[1, 6, 14, 14, USED-FOR], [17, 21, 14, 14, U...</td>\n",
              "      <td>CVPR_2003_10_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[[[27, 29], [55, 55], [70, 72]]]</td>\n",
              "      <td>[[Both, rhetorical, structure, and, punctuatio...</td>\n",
              "      <td>[[[1, 2, OtherScientificTerm], [4, 4, OtherSci...</td>\n",
              "      <td>[[[1, 2, 4, 4, CONJUNCTION], [1, 2, 9, 10, USE...</td>\n",
              "      <td>P06-3008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[[[25, 32], [76, 77], [90, 91]], [[73, 77], [8...</td>\n",
              "      <td>[[The, features, based, on, Markov, random, fi...</td>\n",
              "      <td>[[[1, 1, OtherScientificTerm], [4, 10, Method]...</td>\n",
              "      <td>[[[4, 10, 1, 1, USED-FOR]], [[25, 32, 34, 37, ...</td>\n",
              "      <td>CVPR_2003_11_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[[[60, 64], [79, 79]], [[15, 16], [100, 101]]]</td>\n",
              "      <td>[[Despite, much, recent, progress, on, accurat...</td>\n",
              "      <td>[[[6, 8, Task], [15, 16, Method], [22, 24, Met...</td>\n",
              "      <td>[[[15, 16, 6, 8, USED-FOR], [15, 16, 22, 24, C...</td>\n",
              "      <td>P05-1073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[[[43, 45], [58, 58], [114, 114]], [[50, 55], ...</td>\n",
              "      <td>[[One, of, the, major, problems, one, is, face...</td>\n",
              "      <td>[[[17, 17, OtherScientificTerm], [20, 20, Task...</td>\n",
              "      <td>[[], [[43, 45, 40, 40, USED-FOR], [50, 55, 43,...</td>\n",
              "      <td>E93-1023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[[[27, 27], [53, 53]], [[59, 59], [62, 62]], [...</td>\n",
              "      <td>[[This, paper, describes, the, framework, of, ...</td>\n",
              "      <td>[[[7, 11, Task], [14, 16, Method], [18, 24, Me...</td>\n",
              "      <td>[[[14, 16, 7, 11, USED-FOR], [18, 24, 14, 16, ...</td>\n",
              "      <td>C90-3014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[[[2, 3], [49, 49], [92, 92], [102, 102]], [[6...</td>\n",
              "      <td>[[In, some, auction, domains, ,, there, is, un...</td>\n",
              "      <td>[[[2, 3, Task]], [], [[49, 49, Generic], [52, ...</td>\n",
              "      <td>[[], [], [], [[85, 89, 92, 92, USED-FOR]], [],...</td>\n",
              "      <td>IJCAI_2016_413_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[[[8, 9], [18, 18], [28, 28], [49, 49], [75, 7...</td>\n",
              "      <td>[[In, this, paper, ,, we, will, describe, a, s...</td>\n",
              "      <td>[[[8, 9, Method], [15, 15, OtherScientificTerm...</td>\n",
              "      <td>[[[8, 9, 15, 15, USED-FOR]], [], [], [], [[81,...</td>\n",
              "      <td>C08-3010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[[[42, 43], [47, 47], [58, 59], [74, 75], [96,...</td>\n",
              "      <td>[[For, intelligent, interactive, systems, to, ...</td>\n",
              "      <td>[[[1, 3, Method], [13, 13, Generic]], [[28, 29...</td>\n",
              "      <td>[[], [[28, 29, 32, 32, PART-OF]], [], [], [], ...</td>\n",
              "      <td>J88-3002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[[[0, 2], [25, 25], [47, 47], [58, 60]], [[118...</td>\n",
              "      <td>[[Information, extraction, techniques, automat...</td>\n",
              "      <td>[[[0, 2, Method], [5, 6, Material], [8, 10, Ma...</td>\n",
              "      <td>[[[0, 2, 5, 6, USED-FOR], [8, 10, 0, 2, USED-F...</td>\n",
              "      <td>N04-4028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[[[77, 79], [101, 102]]]</td>\n",
              "      <td>[[In, this, paper, ,, we, use, the, informatio...</td>\n",
              "      <td>[[[7, 11, OtherScientificTerm], [16, 17, Task]...</td>\n",
              "      <td>[[[7, 11, 16, 17, USED-FOR], [7, 11, 24, 25, U...</td>\n",
              "      <td>H05-1005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[[[8, 8], [67, 69], [96, 96], [104, 104], [145...</td>\n",
              "      <td>[[In, this, paper, ,, we, propose, a, new, app...</td>\n",
              "      <td>[[[8, 8, Generic], [11, 16, Task], [20, 21, Me...</td>\n",
              "      <td>[[[8, 8, 11, 16, USED-FOR], [20, 21, 11, 16, E...</td>\n",
              "      <td>ICCV_2015_392_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[This, paper, describes, three, relatively, d...</td>\n",
              "      <td>[[[5, 6, Generic], [11, 15, Method], [17, 18, ...</td>\n",
              "      <td>[[[5, 6, 11, 15, PART-OF], [17, 18, 5, 6, HYPO...</td>\n",
              "      <td>H92-1017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[We, investigate, the, problem, of, fine-grai...</td>\n",
              "      <td>[[[5, 11, Task], [14, 16, OtherScientificTerm]...</td>\n",
              "      <td>[[[14, 16, 23, 26, USED-FOR]], [[74, 77, 87, 8...</td>\n",
              "      <td>CVPR_2016_416_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[[[124, 125], [158, 159]]]</td>\n",
              "      <td>[[In, this, paper, we, target, at, generating,...</td>\n",
              "      <td>[[[7, 9, OtherScientificTerm], [11, 12, Materi...</td>\n",
              "      <td>[[[11, 12, 7, 9, USED-FOR]], [[30, 32, 20, 25,...</td>\n",
              "      <td>CVPR_2015_303_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[[[57, 62], [133, 133]], [[6, 6], [15, 16], [1...</td>\n",
              "      <td>[[This, paper, reports, recent, research, into...</td>\n",
              "      <td>[[[6, 6, Generic], [8, 11, Task]], [[15, 16, G...</td>\n",
              "      <td>[[[6, 6, 8, 11, USED-FOR]], [], [], [[67, 67, ...</td>\n",
              "      <td>J81-1002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[[[52, 52], [65, 66]]]</td>\n",
              "      <td>[[This, paper, explores, the, issue, of, using...</td>\n",
              "      <td>[[[8, 9, OtherScientificTerm], [14, 15, Generi...</td>\n",
              "      <td>[[[8, 9, 14, 15, USED-FOR], [14, 15, 20, 20, U...</td>\n",
              "      <td>E99-1034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[[[4, 6], [27, 27], [126, 126]], [[21, 23], [4...</td>\n",
              "      <td>[[We, propose, a, new, phrase-based, translati...</td>\n",
              "      <td>[[[4, 6, Method], [8, 9, Method], [21, 23, Met...</td>\n",
              "      <td>[[[4, 6, 8, 9, CONJUNCTION]], [[43, 44, 46, 47...</td>\n",
              "      <td>N03-1017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[[[109, 109], [134, 134]], [[32, 33], [95, 96]]]</td>\n",
              "      <td>[[Color, is, known, to, be, highly, discrimina...</td>\n",
              "      <td>[[[9, 11, Task], [19, 20, Material], [24, 24, ...</td>\n",
              "      <td>[[], [[30, 30, 32, 33, USED-FOR], [30, 30, 36,...</td>\n",
              "      <td>CVPR_2011_293_abs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[]</td>\n",
              "      <td>[[We, describe, a, dialogue, system, that, wor...</td>\n",
              "      <td>[[[3, 4, Method]], [[18, 21, Method], [26, 26,...</td>\n",
              "      <td>[[], [[18, 21, 26, 26, USED-FOR], [18, 21, 28,...</td>\n",
              "      <td>P05-3001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02a59b4b-61e4-4ccf-95e3-9be8b5da9807')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02a59b4b-61e4-4ccf-95e3-9be8b5da9807 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02a59b4b-61e4-4ccf-95e3-9be8b5da9807');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dev_data_path = \"/content/drive/MyDrive/fine-turning-dataset/sciNER/dev.json\"\n",
        "df_dev = pd.read_json(dev_data_path, lines=True)\n",
        "df_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EGg19aVPF1KF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265b2eff-6388-4777-b4e6-98cbf315b5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260\n"
          ]
        }
      ],
      "source": [
        "processed_data = []\n",
        "for index, row in df_dev.iterrows():\n",
        "  # if index == 39:\n",
        "  abstract = [\" \".join(i) for i in row[\"sentences\"]]\n",
        "  abstract = \" \".join(abstract)\n",
        "  abstract_list = [item for sublist in row[\"sentences\"] for item in sublist]\n",
        "  \n",
        "  for num in range(len(row[\"sentences\"])):\n",
        "    sentence = row[\"sentences\"][num]\n",
        "    entity_list = row['ner'][num]\n",
        "    if entity_list is not None and len(entity_list) != 0:\n",
        "      text = \" \".join(sentence)\n",
        "      updated_entity_list = []\n",
        "      for entity_tuple in entity_list:\n",
        "        (start, end, label) = entity_tuple\n",
        "        phrase = \" \".join(abstract_list[start:end+1])\n",
        "        phrase = phrase + \" \"\n",
        "        if len(phrase) > 3 and phrase in text:\n",
        "          \n",
        "          updated_entity_list.append((text.index(phrase), text.index(phrase) + len(phrase)-1, label))\n",
        "      \n",
        "      entity = [tuple(sublist)for sublist in updated_entity_list]\n",
        "      data_tuple = (text, entity)\n",
        "      processed_data.append(data_tuple)\n",
        "\n",
        "print(len(processed_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xIC9MA-PF76t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f95712-aaa6-43ea-a54b-6b4a0e5a1004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260\n"
          ]
        }
      ],
      "source": [
        "dev_data = []\n",
        "index = 0\n",
        "for i in processed_data:\n",
        "  text, annotation = i\n",
        "  dev_data.append((text, annotation))\n",
        "\n",
        "print(len(dev_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U65QRYT_GGk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d6fc8b-e70f-47ef-ba6a-1aa836bfbfe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 260/260 [00:00<00:00, 1560.15it/s]\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "db = DocBin()\n",
        "index = 0\n",
        "for i in tqdm(dev_data):\n",
        "  index += 1\n",
        "  for text, annotations in [i]:\n",
        "      try:\n",
        "        doc = nlp(text)\n",
        "        ents = []\n",
        "        for start, end, label in annotations:\n",
        "            span = doc.char_span(start, end, label=label)\n",
        "            ents.append(span)\n",
        "        doc.ents = ents\n",
        "        db.add(doc)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "db.to_disk(\"/content/dev.spacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tbwwE82CCHU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c55bfef-dbed-49c1-8ce4-5cadf21a0136"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "db = DocBin()\n",
        "db.from_disk(\"/content/dev.spacy\")\n",
        "len(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JZ1nEDGGRHx"
      },
      "source": [
        "# fine-turning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr2uJsjKHjqc"
      },
      "outputs": [],
      "source": [
        "!pip install scispacy\n",
        "!pip install spacy-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "r-TrM_qVpVIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80caf442-8bd7-4161-f191-dca97af51487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/content/config_spacy.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config_spacy.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy init fill-config /content/base_config.cfg /content/config_spacy.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yaaeaaHYBEH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f5eb53-d3bf-49eb-e7fe-7955acfd65db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: /content/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: /content/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-11-24 18:18:22,491] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-11-24 18:18:22,502] [INFO] Pipeline: ['transformer', 'ner']\n",
            "INFO:spacy:Pipeline: ['transformer', 'ner']\n",
            "[2022-11-24 18:18:22,502] [INFO] Resuming training for: ['ner']\n",
            "INFO:spacy:Resuming training for: ['ner']\n",
            "[2022-11-24 18:18:22,507] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2022-11-24 18:18:22,508] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "Downloading config.json: 100% 481/481 [00:00<00:00, 444kB/s]\n",
            "Downloading vocab.json: 100% 878k/878k [00:00<00:00, 982kB/s] \n",
            "Downloading merges.txt: 100% 446k/446k [00:00<00:00, 497kB/s]\n",
            "Downloading tokenizer.json: 100% 1.29M/1.29M [00:00<00:00, 1.46MB/s]\n",
            "Downloading pytorch_model.bin: 100% 478M/478M [00:06<00:00, 74.9MB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-11-24 18:18:48,277] [INFO] Initialized pipeline components: ['transformer']\n",
            "INFO:spacy:Initialized pipeline components: ['transformer']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        1633.66    531.62    0.00    0.00    0.00    0.00\n",
            "  6     200       57816.41  50353.14    0.00    0.00    0.00    0.00\n",
            " 13     400       17277.78  47921.83    2.70    2.81    2.60    0.03\n",
            " 20     600       12468.81  40198.66   17.49   16.80   18.23    0.17\n",
            " 27     800       11036.63  35381.26   16.05   19.01   13.89    0.16\n",
            " 33    1000        8606.07  35488.97   24.34   22.32   26.77    0.24\n",
            " 40    1200        8708.06  36362.97   32.52   32.33   32.71    0.33\n",
            " 47    1400       11238.94  43916.67   30.87   30.63   31.11    0.31\n",
            " 54    1600        7723.60  41831.98   29.44   28.05   30.97    0.29\n",
            " 60    1800       11251.31  41233.72   34.74   31.96   38.06    0.35\n",
            " 67    2000        6976.86  44086.22   32.72   36.48   29.67    0.33\n",
            " 74    2200        4885.70  39308.80   32.88   32.62   33.14    0.33\n",
            " 81    2400        4233.63  33593.77   35.96   33.63   38.64    0.36\n",
            " 87    2600        6338.34  31784.95   40.72   40.49   40.96    0.41\n",
            " 94    2800        5502.46  34027.63   36.38   33.92   39.22    0.36\n",
            "101    3000        8323.00  40639.81   37.56   36.41   38.78    0.38\n",
            "108    3200       13371.16  45751.19   33.24   33.63   32.85    0.33\n",
            "114    3400       17475.98  38624.19   39.35   38.38   40.38    0.39\n",
            "121    3600        6137.15  38003.90   36.80   35.74   37.92    0.37\n",
            "128    3800        5387.64  34955.97   44.16   44.03   44.28    0.44\n",
            "135    4000       24390.95  20907.40   39.43   37.07   42.11    0.39\n",
            "142    4200        2425.58  22869.46   46.51   45.33   47.76    0.47\n",
            "148    4400        2952.75  22134.83   42.87   41.67   44.14    0.43\n",
            "155    4600        5167.07  29819.59   27.50   26.82   28.22    0.28\n",
            "162    4800        6475.07  33290.89   45.33   43.14   47.76    0.45\n",
            "169    5000        5544.29  27781.56   54.03   53.23   54.85    0.54\n",
            "176    5200        3201.86  20098.05   52.13   49.67   54.85    0.52\n",
            "182    5400        4727.82  23058.20   43.99   42.76   45.30    0.44\n",
            "189    5600        3407.87  18046.12   53.52   53.06   53.98    0.54\n",
            "196    5800        2608.21  15469.48   61.57   60.25   62.95    0.62\n",
            "202    6000         878.06   7089.25   62.55   60.68   64.54    0.63\n",
            "209    6200         948.52   5604.19   65.15   63.93   66.43    0.65\n",
            "216    6400        2106.02   5800.36   60.86   58.66   63.24    0.61\n",
            "222    6600        1368.12   4797.32   62.14   60.80   63.53    0.62\n",
            "229    6800         974.19   3351.01   66.71   64.80   68.74    0.67\n",
            "236    7000         984.04   2566.38   65.46   63.21   67.87    0.65\n",
            "243    7200        1266.80   2455.05   63.53   61.75   65.41    0.64\n",
            "249    7400        1125.73   2043.21   63.92   61.84   66.14    0.64\n",
            "256    7600        1091.41   1675.66   65.64   63.43   68.02    0.66\n",
            "263    7800         554.58    846.80   66.15   64.90   67.44    0.66\n",
            "270    8000         449.41    524.81   66.15   64.26   68.16    0.66\n",
            "276    8200         291.01    318.48   66.81   64.98   68.74    0.67\n",
            "283    8400         336.40    220.85   67.14   65.61   68.74    0.67\n",
            "290    8600         250.58    203.20   66.81   64.98   68.74    0.67\n",
            "297    8800         259.73    209.72   67.14   66.29   68.02    0.67\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/output/model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train /content/config_spacy.cfg --output /content/output --paths.train /content/train.spacy --paths.dev /content/dev.spacy --gpu-id 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "WBRVWla4qNVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69eb0bd-e2ee-4afe-fd0a-328f9aa9a1c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stable Diffusion Method\n",
            "deep learning, text-to-image model Method\n",
            "StabilityAI Method\n",
            "text descriptions OtherScientificTerm\n",
            "tasks Generic\n",
            "inpainting Task\n",
            "outpainting Task\n",
            "generating image-to-image translations Task\n",
            "text prompt OtherScientificTerm\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"/content/drive/MyDrive/fine-turning-dataset/sciNER_fineturn/roBERTa/output/model-best\")\n",
        "cs_text = \"\"\"\n",
        "Stable Diffusion is a deep learning, text-to-image model released by startup StabilityAI in 2022. \n",
        "It is primarily used to generate detailed images conditioned on text descriptions, \n",
        "though it can also be applied to other tasks such as inpainting, outpainting, and generating image-to-image translations guided by a text prompt.\n",
        "\"\"\"\n",
        "output = nlp(cs_text)\n",
        "for ent in output.ents:\n",
        "  print(ent.text, ent.label_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/fine_turned_output.zip /content/output"
      ],
      "metadata": {
        "id": "GfhWJaqSq5uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/fine_turned_output.zip\")"
      ],
      "metadata": {
        "id": "IGtTEd2OrE7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "7bjAP6kPllHk",
        "7_0fL1ateVm_",
        "ZE1_vyuUeamm"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}